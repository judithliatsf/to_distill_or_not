{"cells":[{"cell_type":"markdown","source":["The current notebook requires TF2 to run (see [databricks 6.1ML Runtime for how to install TF2](https://docs.databricks.com/applications/deep-learning/single-node-training/tensorflow.html#install-tensorflow-20-on-dbr-61-ml))"],"metadata":{}},{"cell_type":"markdown","source":["TODO\n- [] Add tf.summary to monitor all statistics in tensorboard (see [tutorial](https://www.tensorflow.org/tensorboard/migrate))\n- [x] Change how inference is done: currently no mask is used when validation accuracy is measured\n- [x] Add an option to use MSE LOSS\n- [x] Add a function to load initializations from the teacher model to the student model"],"metadata":{}},{"cell_type":"code","source":["import tensorflow as tf\nimport tensorflow_datasets\nfrom transformers import *\nimport tensorflow_hub as hub\nimport sys"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n  from collections import Mapping, MutableMapping\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["print(tf.__version__)\nprint(hub.__version__)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2.0.0\n0.7.0\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["Define DistillBertConfig as a subclass of BertConfig and DistilConfig to incorporate the following parameters"],"metadata":{}},{"cell_type":"code","source":["class DistilMyBertConfig(PretrainedConfig):\n    def __init__(self,\n                 vocab_size_or_config_json_file=33333,\n                 num_classes=2,\n                 distill_temperature=2.0,\n                 task_balance=0.5,\n                 max_seq_len=128,\n                 epoch = 5,\n                 learning_rate=5e-4,\n                 adam_epsilon=1e-6,\n                 max_grad_norm=5.0,\n                 **kwargs):\n        super(PretrainedConfig, self).__init__(*kwargs)\n        \n        if isinstance(vocab_size_or_config_json_file, str) or (sys.version_info[0] == 2\n                        and isinstance(vocab_size_or_config_json_file, unicode)):\n            with open(vocab_size_or_config_json_file, \"r\", encoding='utf-8') as reader:\n                json_config = json.loads(reader.read())\n            for key, value in json_config.items():\n                self.__dict__[key] = value\n        elif isinstance(vocab_size_or_config_json_file, int):\n            self.num_classes=num_classes\n            self.distill_temperature = distill_temperature\n            self.task_balance = task_balance\n            self.max_seq_len = max_seq_len\n            self.epoch = epoch\n            self.learning_rate = learning_rate\n            self.adam_epsilon = adam_epsilon\n            self.max_grad_norm = max_grad_norm"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Prepare Config\nconfig = DistilMyBertConfig()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Get stuent and teacher nn architecture\n\nstudent_config_class, student_model_class, student_tokenizer_class = DistilBertConfig, TFDistilBertForSequenceClassification, DistilBertTokenizer\nteacher_config_class, teacher_model_class, teacher_tokenizer_class = BertConfig, TFBertForSequenceClassification, BertTokenizer\n\n# Load teacher model from checkpoints, but freeze the teacher layers\nteacher = teacher_model_class.from_pretrained(\"/dbfs/ml/judith/transformers/mrpc/1\")#, output_hidden_states=True)\nteacher_tokenizer = teacher_tokenizer_class.from_pretrained('/dbfs/ml/judith/transformers/mrpc/1') \n\n# # Load student model from config\n# # Student model no longer has token type embedding and the position embedding\n# student_config_path = \"/dbfs/ml/judith/transformers/distilbert-base-uncased.json\"\n# stu_architecture_config = student_config_class.from_pretrained(student_config_path)\n# stu_architecture_config.sinusoidal_pos_embds = False\n# stu_architecture_config.n_layers = 1\n# student = student_model_class(stu_architecture_config)\n# print(\"Is the student weights are empty before training? \", student.weights==[])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Is the student weights are empty before training?  True\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["teacher_config = teacher_config_class.from_pretrained('bert-base-uncased')\nteacher_config.num_hidden_layers = 1\nstudent = teacher_model_class(teacher_config)\nprint(\"Is the teacher model weights are empty before training? \", student.weights==[])\nstudent(student.dummy_inputs, training=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Is the teacher model weights are empty before training?  True\nOut[113]: (&lt;tf.Tensor: id=606639, shape=(3, 2), dtype=float32, numpy=\n array([[-0.17411079, -0.03499376],\n        [-0.28216106, -0.16699678],\n        [ 0.02154749, -0.17930067]], dtype=float32)&gt;,)</div>"]}}],"execution_count":9},{"cell_type":"code","source":["student.load_weights('/tmp/experiment3/teacher/tf_model.h5', by_name=True)\nstudent(student.dummy_inputs, training=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-145929&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>student<span class=\"ansi-blue-fg\">.</span>load_weights<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;/tmp/experiment3/teacher/tf_model.h5&#39;</span><span class=\"ansi-blue-fg\">,</span> by_name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> student<span class=\"ansi-blue-fg\">(</span>student<span class=\"ansi-blue-fg\">.</span>dummy_inputs<span class=\"ansi-blue-fg\">,</span> training<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py</span> in <span class=\"ansi-cyan-fg\">load_weights</span><span class=\"ansi-blue-fg\">(self, filepath, by_name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    179</span>         raise ValueError(&#39;Load weights is not yet supported with TPUStrategy &#39;\n<span class=\"ansi-green-intense-fg ansi-bold\">    180</span>                          &#39;with steps_per_run greater than 1.&#39;)\n<span class=\"ansi-green-fg\">--&gt; 181</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> super<span class=\"ansi-blue-fg\">(</span>Model<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load_weights<span class=\"ansi-blue-fg\">(</span>filepath<span class=\"ansi-blue-fg\">,</span> by_name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>   <span class=\"ansi-blue-fg\">@</span>trackable<span class=\"ansi-blue-fg\">.</span>no_automatic_dependency_tracking\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py</span> in <span class=\"ansi-cyan-fg\">load_weights</span><span class=\"ansi-blue-fg\">(self, filepath, by_name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1173</span>         f <span class=\"ansi-blue-fg\">=</span> f<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;model_weights&#39;</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1174</span>       <span class=\"ansi-green-fg\">if</span> by_name<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1175</span><span class=\"ansi-red-fg\">         </span>saving<span class=\"ansi-blue-fg\">.</span>load_weights_from_hdf5_group_by_name<span class=\"ansi-blue-fg\">(</span>f<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>layers<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1176</span>       <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1177</span>         saving<span class=\"ansi-blue-fg\">.</span>load_weights_from_hdf5_group<span class=\"ansi-blue-fg\">(</span>f<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>layers<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py</span> in <span class=\"ansi-cyan-fg\">load_weights_from_hdf5_group_by_name</span><span class=\"ansi-blue-fg\">(f, layers)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    749</span>                          <span class=\"ansi-blue-fg\">&#39;&#34;) expects &#39;</span> <span class=\"ansi-blue-fg\">+</span> str<span class=\"ansi-blue-fg\">(</span>len<span class=\"ansi-blue-fg\">(</span>symbolic_weights<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    750</span>                          <span class=\"ansi-blue-fg\">&#39; weight(s), but the saved weights&#39;</span> <span class=\"ansi-blue-fg\">+</span> <span class=\"ansi-blue-fg\">&#39; have &#39;</span> <span class=\"ansi-blue-fg\">+</span>\n<span class=\"ansi-green-fg\">--&gt; 751</span><span class=\"ansi-red-fg\">                          str(len(weight_values)) + &#39; element(s).&#39;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    752</span>       <span class=\"ansi-red-fg\"># Set values.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>       <span class=\"ansi-green-fg\">for</span> i <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span>len<span class=\"ansi-blue-fg\">(</span>weight_values<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">ValueError</span>: Layer #0 (named &#34;bert&#34;) expects 23 weight(s), but the saved weights have 199 element(s).</div>"]}}],"execution_count":10},{"cell_type":"code","source":["print(student(student.dummy_inputs, training=False))\nlayer_mapping = {0:0}\nextract_weights_from_teacher(teacher, student, layer_mapping)\n# student(student.dummy_inputs, training=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&lt;tf.Tensor: id=606877, shape=(3, 2), dtype=float32, numpy=\narray([[-0.17411079, -0.03499376],\n       [-0.28216106, -0.16699678],\n       [ 0.02154749, -0.17930067]], dtype=float32)&gt;,)\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["student(student.dummy_inputs, training=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[115]: (&lt;tf.Tensor: id=607115, shape=(3, 2), dtype=float32, numpy=\n array([[-0.17411079, -0.03499376],\n        [-0.28216106, -0.16699678],\n        [ 0.02154749, -0.17930067]], dtype=float32)&gt;,)</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# save pre-trained weights\nteacher = teacher_model_class.from_pretrained('bert-base-uncased')\nteacher.save_pretrained('/tmp/experiment3/teacher')\n\n# build teacher architecture\nteacher_config = teacher_config_class.from_pretrained('bert-base-uncased')\nteacher = teacher_model_class(teacher_config)\nteacher(teacher.dummy_inputs, training=False)\n\n# initialize teacher from pre-trained weights\nteacher.load_weights('/tmp/experiment3/teacher/tf_model.h5')\nteacher(teacher.dummy_inputs, training=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[80]: (&lt;tf.Tensor: id=364163, shape=(3, 2), dtype=float32, numpy=\n array([[-0.25553346,  0.01401245],\n        [-0.18620504,  0.12456853],\n        [-0.05898177,  0.18377906]], dtype=float32)&gt;,)</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# num_hidden_layers = 1\n# training=True\n\n# teacher = teacher_model_class.from_pretrained('bert-base-uncased')\n\n# input_ids = tf.keras.layers.Input(shape=(config.max_seq_len,), dtype=tf.int32,\n#                                        name=\"input_word_ids\")\n# attention_mask = tf.keras.layers.Input(shape=(config.max_seq_len,), dtype=tf.int32,\n#                                    name=\"attention_mask\")\n# token_type_ids = tf.keras.layers.Input(shape=(config.max_seq_len,), dtype=tf.int32,\n#                                     name=\"token_type_ids\")\n\n# extended_attention_mask = attention_mask[:, tf.newaxis, tf.newaxis, :]\n# extended_attention_mask = tf.cast(extended_attention_mask, tf.float32)\n# extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n# head_mask = [None] * num_hidden_layers\n# position_ids = None\n\n# embedding_output = teacher.bert.embeddings([input_ids, position_ids, token_type_ids], training=training)\n# encoder_outputs = teacher.bert.encoder.layer[0]([embedding_output, extended_attention_mask, head_mask], training=training)\n\n# sequence_output = encoder_outputs[0]\n# pooled_output = teacher.bert.pooler(sequence_output)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-145935&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     18</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     19</span> embedding_output <span class=\"ansi-blue-fg\">=</span> teacher<span class=\"ansi-blue-fg\">.</span>bert<span class=\"ansi-blue-fg\">.</span>embeddings<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>input_ids<span class=\"ansi-blue-fg\">,</span> position_ids<span class=\"ansi-blue-fg\">,</span> token_type_ids<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> training<span class=\"ansi-blue-fg\">=</span>training<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 20</span><span class=\"ansi-red-fg\"> </span>encoder_outputs <span class=\"ansi-blue-fg\">=</span> teacher<span class=\"ansi-blue-fg\">.</span>bert<span class=\"ansi-blue-fg\">.</span>encoder<span class=\"ansi-blue-fg\">.</span>layer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>embedding_output<span class=\"ansi-blue-fg\">,</span> extended_attention_mask<span class=\"ansi-blue-fg\">,</span> head_mask<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> training<span class=\"ansi-blue-fg\">=</span>training<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     21</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     22</span> sequence_output <span class=\"ansi-blue-fg\">=</span> encoder_outputs<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, inputs, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    889</span>           with base_layer_utils.autocast_context_manager(\n<span class=\"ansi-green-intense-fg ansi-bold\">    890</span>               self._compute_dtype):\n<span class=\"ansi-green-fg\">--&gt; 891</span><span class=\"ansi-red-fg\">             </span>outputs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>call<span class=\"ansi-blue-fg\">(</span>cast_inputs<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    892</span>           self<span class=\"ansi-blue-fg\">.</span>_handle_activity_regularization<span class=\"ansi-blue-fg\">(</span>inputs<span class=\"ansi-blue-fg\">,</span> outputs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    893</span>           self<span class=\"ansi-blue-fg\">.</span>_set_mask_metadata<span class=\"ansi-blue-fg\">(</span>inputs<span class=\"ansi-blue-fg\">,</span> outputs<span class=\"ansi-blue-fg\">,</span> input_masks<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/transformers/modeling_tf_bert.py</span> in <span class=\"ansi-cyan-fg\">call</span><span class=\"ansi-blue-fg\">(self, inputs, training)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    329</span>         hidden_states<span class=\"ansi-blue-fg\">,</span> attention_mask<span class=\"ansi-blue-fg\">,</span> head_mask <span class=\"ansi-blue-fg\">=</span> inputs\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span> \n<span class=\"ansi-green-fg\">--&gt; 331</span><span class=\"ansi-red-fg\">         </span>attention_outputs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>attention<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>hidden_states<span class=\"ansi-blue-fg\">,</span> attention_mask<span class=\"ansi-blue-fg\">,</span> head_mask<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> training<span class=\"ansi-blue-fg\">=</span>training<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    332</span>         attention_output <span class=\"ansi-blue-fg\">=</span> attention_outputs<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    333</span>         intermediate_output <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>intermediate<span class=\"ansi-blue-fg\">(</span>attention_output<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, inputs, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    889</span>           with base_layer_utils.autocast_context_manager(\n<span class=\"ansi-green-intense-fg ansi-bold\">    890</span>               self._compute_dtype):\n<span class=\"ansi-green-fg\">--&gt; 891</span><span class=\"ansi-red-fg\">             </span>outputs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>call<span class=\"ansi-blue-fg\">(</span>cast_inputs<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    892</span>           self<span class=\"ansi-blue-fg\">.</span>_handle_activity_regularization<span class=\"ansi-blue-fg\">(</span>inputs<span class=\"ansi-blue-fg\">,</span> outputs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    893</span>           self<span class=\"ansi-blue-fg\">.</span>_set_mask_metadata<span class=\"ansi-blue-fg\">(</span>inputs<span class=\"ansi-blue-fg\">,</span> outputs<span class=\"ansi-blue-fg\">,</span> input_masks<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/transformers/modeling_tf_bert.py</span> in <span class=\"ansi-cyan-fg\">call</span><span class=\"ansi-blue-fg\">(self, inputs, training)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    278</span>         input_tensor<span class=\"ansi-blue-fg\">,</span> attention_mask<span class=\"ansi-blue-fg\">,</span> head_mask <span class=\"ansi-blue-fg\">=</span> inputs\n<span class=\"ansi-green-intense-fg ansi-bold\">    279</span> \n<span class=\"ansi-green-fg\">--&gt; 280</span><span class=\"ansi-red-fg\">         </span>self_outputs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>self_attention<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>input_tensor<span class=\"ansi-blue-fg\">,</span> attention_mask<span class=\"ansi-blue-fg\">,</span> head_mask<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> training<span class=\"ansi-blue-fg\">=</span>training<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    281</span>         attention_output <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>dense_output<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>self_outputs<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> input_tensor<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> training<span class=\"ansi-blue-fg\">=</span>training<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    282</span>         outputs <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">(</span>attention_output<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">+</span> self_outputs<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span>  <span class=\"ansi-red-fg\"># add attentions if we output them</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, inputs, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    889</span>           with base_layer_utils.autocast_context_manager(\n<span class=\"ansi-green-intense-fg ansi-bold\">    890</span>               self._compute_dtype):\n<span class=\"ansi-green-fg\">--&gt; 891</span><span class=\"ansi-red-fg\">             </span>outputs <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>call<span class=\"ansi-blue-fg\">(</span>cast_inputs<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    892</span>           self<span class=\"ansi-blue-fg\">.</span>_handle_activity_regularization<span class=\"ansi-blue-fg\">(</span>inputs<span class=\"ansi-blue-fg\">,</span> outputs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    893</span>           self<span class=\"ansi-blue-fg\">.</span>_set_mask_metadata<span class=\"ansi-blue-fg\">(</span>inputs<span class=\"ansi-blue-fg\">,</span> outputs<span class=\"ansi-blue-fg\">,</span> input_masks<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/transformers/modeling_tf_bert.py</span> in <span class=\"ansi-cyan-fg\">call</span><span class=\"ansi-blue-fg\">(self, inputs, training)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    236</span>         <span class=\"ansi-red-fg\"># Mask heads if we want to</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    237</span>         <span class=\"ansi-green-fg\">if</span> head_mask <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 238</span><span class=\"ansi-red-fg\">             </span>attention_probs <span class=\"ansi-blue-fg\">=</span> attention_probs <span class=\"ansi-blue-fg\">*</span> head_mask\n<span class=\"ansi-green-intense-fg ansi-bold\">    239</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    240</span>         context_layer <span class=\"ansi-blue-fg\">=</span> tf<span class=\"ansi-blue-fg\">.</span>matmul<span class=\"ansi-blue-fg\">(</span>attention_probs<span class=\"ansi-blue-fg\">,</span> value_layer<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py</span> in <span class=\"ansi-cyan-fg\">binary_op_wrapper</span><span class=\"ansi-blue-fg\">(x, y)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    901</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    902</span>           y = ops.convert_to_tensor_v2(\n<span class=\"ansi-green-fg\">--&gt; 903</span><span class=\"ansi-red-fg\">               y, dtype_hint=x.dtype.base_dtype, name=&#34;y&#34;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    904</span>         <span class=\"ansi-green-fg\">except</span> TypeError<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    905</span>           <span class=\"ansi-red-fg\"># If the RHS is not a tensor, it might be a tensor aware object</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py</span> in <span class=\"ansi-cyan-fg\">convert_to_tensor_v2</span><span class=\"ansi-blue-fg\">(value, dtype, dtype_hint, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1240</span>       name<span class=\"ansi-blue-fg\">=</span>name<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1241</span>       preferred_dtype<span class=\"ansi-blue-fg\">=</span>dtype_hint<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">-&gt; 1242</span><span class=\"ansi-red-fg\">       as_ref=False)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1243</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1244</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py</span> in <span class=\"ansi-cyan-fg\">internal_convert_to_tensor</span><span class=\"ansi-blue-fg\">(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1294</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1295</span>     <span class=\"ansi-green-fg\">if</span> ret <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1296</span><span class=\"ansi-red-fg\">       </span>ret <span class=\"ansi-blue-fg\">=</span> conversion_func<span class=\"ansi-blue-fg\">(</span>value<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">=</span>name<span class=\"ansi-blue-fg\">,</span> as_ref<span class=\"ansi-blue-fg\">=</span>as_ref<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1297</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1298</span>     <span class=\"ansi-green-fg\">if</span> ret <span class=\"ansi-green-fg\">is</span> NotImplemented<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py</span> in <span class=\"ansi-cyan-fg\">_constant_tensor_conversion_function</span><span class=\"ansi-blue-fg\">(v, dtype, name, as_ref)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    284</span>                                          as_ref=False):\n<span class=\"ansi-green-intense-fg ansi-bold\">    285</span>   _ <span class=\"ansi-blue-fg\">=</span> as_ref\n<span class=\"ansi-green-fg\">--&gt; 286</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-green-fg\">return</span> constant<span class=\"ansi-blue-fg\">(</span>v<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">=</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    287</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    288</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py</span> in <span class=\"ansi-cyan-fg\">constant</span><span class=\"ansi-blue-fg\">(value, dtype, shape, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    225</span>   &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    226</span>   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n<span class=\"ansi-green-fg\">--&gt; 227</span><span class=\"ansi-red-fg\">                         allow_broadcast=True)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    228</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    229</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py</span> in <span class=\"ansi-cyan-fg\">_constant_impl</span><span class=\"ansi-blue-fg\">(value, dtype, shape, name, verify_shape, allow_broadcast)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    233</span>   ctx <span class=\"ansi-blue-fg\">=</span> context<span class=\"ansi-blue-fg\">.</span>context<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    234</span>   <span class=\"ansi-green-fg\">if</span> ctx<span class=\"ansi-blue-fg\">.</span>executing_eagerly<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 235</span><span class=\"ansi-red-fg\">     </span>t <span class=\"ansi-blue-fg\">=</span> convert_to_eager_tensor<span class=\"ansi-blue-fg\">(</span>value<span class=\"ansi-blue-fg\">,</span> ctx<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    236</span>     <span class=\"ansi-green-fg\">if</span> shape <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    237</span>       <span class=\"ansi-green-fg\">return</span> t\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py</span> in <span class=\"ansi-cyan-fg\">convert_to_eager_tensor</span><span class=\"ansi-blue-fg\">(value, ctx, dtype)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     94</span>       dtype <span class=\"ansi-blue-fg\">=</span> dtypes<span class=\"ansi-blue-fg\">.</span>as_dtype<span class=\"ansi-blue-fg\">(</span>dtype<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>as_datatype_enum\n<span class=\"ansi-green-intense-fg ansi-bold\">     95</span>   ctx<span class=\"ansi-blue-fg\">.</span>ensure_initialized<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 96</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-green-fg\">return</span> ops<span class=\"ansi-blue-fg\">.</span>EagerTensor<span class=\"ansi-blue-fg\">(</span>value<span class=\"ansi-blue-fg\">,</span> ctx<span class=\"ansi-blue-fg\">.</span>device_name<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     97</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     98</span> \n\n<span class=\"ansi-red-fg\">ValueError</span>: Attempt to convert a value (None) with an unsupported type (&lt;class &#39;NoneType&#39;&gt;) to a Tensor.</div>"]}}],"execution_count":14},{"cell_type":"code","source":["%sh\nls /tmp/experiment3/teacher"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">config.json\ntf_model.h5\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["# layer_num = 0\n# print(\"the {}th encoder layer has {} variables and {} trainable variables\".format(\n#   layer_num,\n#   len(teacher.layers[0].encoder.layer[layer_num].variables),\n#   len(teacher.layers[0].encoder.layer[layer_num].trainable_variables)\n# ))\n\n# print(\"the inputs are transformed by embeddings layer first\")\n# for v in teacher.bert.embeddings.variables:\n#   print(v.name)\n  \n# print(\"each encoder layer has attention, intermediate and bert_output layer\")\n# for v in teacher.bert.encoder.layer[layer_num].attention.variables:\n#   print(v.name)\n  \n# for v in teacher.bert.encoder.layer[layer_num].intermediate.variables:\n#   print(v.name)\n\n# for v in teacher.bert.encoder.layer[layer_num].bert_output.variables:\n#   print(v.name)\n\n# print(\"the output of the encoder is a sequence output then is transformed into a pooled output through a pooler layer on top\")\n# for v in teacher.bert.pooler.variables:\n#   print(v.name)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">the 0th encoder layer has 16 variables and 16 trainable variables\neach encoder layer has attention, intermediate and bert_output layer\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0\ntf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0\ntf_bert_for_sequence_classification/bert/pooler/dense/kernel:0\ntf_bert_for_sequence_classification/bert/pooler/dense/bias:0\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["def extract_weights_from_teacher(teacher, student, layer_maps):\n  \"\"\"Extract the weights from teacher to initialize the student layer\n  \n  Args:\n    teacher: BertSequenceClassifier\n    student: BertSequenceClassifier\n    layer_maps: e.g., {s: t} will initialize s'th student\n                encoder layer using the weights from t'th teacher encoder layer\n  \"\"\"\n  # copy the embedding weights\n  for v in teacher.bert.embeddings.variables:\n    student.bert.embeddings.add_weight(\n      name=v.name,\n      shape=v.shape,\n      dtype=v.dtype,\n      trainable=True,\n      getter=lambda *_, **__: v\n    )\n\n  # initialize the student layer (s_layer_num) using the teacher layer number (layer_num)\n  layer_num = 0\n  s_layer_num = 0\n  for s, t in layer_maps.items():\n    # copy the encoder weights\n\n    for v in teacher.bert.encoder.layer[t].attention.variables:\n      student.bert.encoder.layer[s].add_weight(\n        name=v.name,\n        shape=v.shape,\n        dtype=v.dtype,\n        trainable=True,\n        getter=lambda *_, **__: v\n      )\n\n    for v in teacher.bert.encoder.layer[t].intermediate.variables:\n      student.bert.encoder.layer[s].add_weight(\n        name = v.name, \n        shape = v.shape,\n        dtype=v.dtype,\n        trainable=True,\n        getter=lambda *_, **__: v\n      )\n\n    for v in teacher.bert.encoder.layer[t].bert_output.variables:\n      student.bert.encoder.layer[s].add_weight(\n        name=v.name,\n        shape=v.shape,\n        dtype=v.dtype,\n        trainable=True,\n        getter=lambda *_, **__: v\n      )\n\n  # copy the pooler weights\n  for v in teacher.bert.pooler.variables:\n    student.bert.pooler.add_weight(\n      name=v.name,\n      shape=v.shape,\n      dtype=v.dtype,\n      trainable=True,\n      getter=lambda *_, **__: v\n    )\n    \n#   # Forward the callable's regularization losses (if any).\n#   if hasattr(teacher, \"regularization_losses\"):\n#     for l in self._func.regularization_losses:\n#       if not callable(l):\n#         raise ValueError(\n#             \"hub.KerasLayer(obj) expects obj.regularization_losses to be an \"\n#             \"iterable of callables, each returning a scalar loss term.\")\n#       self.add_loss(self._call_loss_if_trainable(l))  # Supports callables."],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["# input_ids = tf.keras.layers.Input(shape=(config.max_seq_len,), dtype=tf.int32, name=\"input_ids\")\n# student_logits = student(input_ids)\n# student_model = tf.keras.Model(inputs=input_ids,\n#                        outputs=student_logits)\n\n# teacher_input_ids = tf.keras.layers.Input(shape=(config.max_seq_len,), dtype=tf.int32, name=\"teacher_input_ids\")\n# teacher_logits = teacher(teacher_input_ids)\n# teacher_model = tf.keras.Model(inputs=teacher_input_ids,\n#                                outputs=teacher_logits)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["teacher.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model: &#34;tf_bert_for_sequence_classification&#34;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbert (TFBertMainLayer)       multiple                  108310272 \n_________________________________________________________________\ndropout_37 (Dropout)         multiple                  0         \n_________________________________________________________________\nclassifier (Dense)           multiple                  1538      \n=================================================================\nTotal params: 108,311,810\nTrainable params: 108,311,810\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["student.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model: &#34;tf_bert_for_sequence_classification_20&#34;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbert (TFBertMainLayer)       multiple                  31515648  \n_________________________________________________________________\ndropout_510 (Dropout)        multiple                  0         \n_________________________________________________________________\nclassifier (Dense)           multiple                  1538      \n=================================================================\nTotal params: 31,517,186\nTrainable params: 31,517,186\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["Prepare Data from MRPC"],"metadata":{}},{"cell_type":"code","source":["data = tensorflow_datasets.load('glue/mrpc')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">INFO:absl:Load pre-computed datasetinfo (eg: splits) from bucket.\nINFO:absl:Loading info from GCS for glue/mrpc/0.0.2\nINFO:absl:Generating dataset glue (/root/tensorflow_datasets/glue/mrpc/0.0.2)\n<span class=\"ansi-bold\">Downloading and preparing dataset glue (1.43 MiB) to /root/tensorflow_datasets/glue/mrpc/0.0.2...</span>\n\rDl Completed...: 0 url [00:00, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&amp;token=ec5c0836-31d5-48f4-b431-7480817f1adc into /root/tensorflow_datasets/downloads/fire.goog.com_v0_b_mtl-sent-repr.apps.com_o_2FjSIMlCiqs1QSmIykr4IRPnEHjPuGwAz5i40v8K9U0Z8.tsvalt=media&amp;token=ec5c0836-31d5-48f4-b431-7480817f1adc.tmp.fa5987007dbe4ad0a52a1a195022d3c6...\n\rDl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt into /root/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_trainfGxPZuQWGBti4Tbd1YNOwQr-OqxPejJ7gcp0Al6mlSk.txt.tmp.35ed895be7954d0abd5d23359aea31a1...\n\rDl Completed...:   0%|          | 0/2 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt into /root/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_test0PdekMcyqYR-w4Rx_d7OTryq0J3RlYRn4rAMajy9Mak.txt.tmp.2e1be8f75f9f44aca1ba63f37f1a52c7...\n\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  2.55 url/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  2.55 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  67%|██████▋   | 2/3 [00:00&lt;00:00,  2.55 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...: 100%|██████████| 3/3 [00:00&lt;00:00,  2.55 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\rDl Completed...: 100%|██████████| 3/3 [00:00&lt;00:00,  6.46 url/s]\nINFO:absl:Generating split train\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r250 examples [00:00, 2497.87 examples/s]\r510 examples [00:00, 2525.47 examples/s]\r774 examples [00:00, 2556.17 examples/s]\r1023 examples [00:00, 2533.54 examples/s]\r1286 examples [00:00, 2559.99 examples/s]\r1549 examples [00:00, 2579.22 examples/s]\r1819 examples [00:00, 2612.82 examples/s]\r2088 examples [00:00, 2635.16 examples/s]\r2343 examples [00:00, 2608.13 examples/s]\r2609 examples [00:01, 2622.08 examples/s]\r2879 examples [00:01, 2643.93 examples/s]\r3140 examples [00:01, 2633.05 examples/s]\r3400 examples [00:01, 2606.93 examples/s]\r3659 examples [00:01, 2589.45 examples/s]\r                                         \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\n\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/3668 [00:00&lt;?, ? examples/s]\n\r                                                           \r                                                       \rINFO:absl:Generating split validation\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r151 examples [00:00, 1498.93 examples/s]\r303 examples [00:00, 1503.85 examples/s]\r                                        \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/408 [00:00&lt;?, ? examples/s]\n\r                                                          \r                                                       \rINFO:absl:Generating split test\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r290 examples [00:00, 2899.63 examples/s]\r551 examples [00:00, 2804.47 examples/s]\r847 examples [00:00, 2848.65 examples/s]\r1137 examples [00:00, 2863.62 examples/s]\r1430 examples [00:00, 2880.76 examples/s]\r1713 examples [00:00, 2862.93 examples/s]\r                                         \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/1725 [00:00&lt;?, ? examples/s]\n\r                                                           \r                                                       \rINFO:absl:Skipping computing stats for mode ComputeStatsMode.AUTO.\n<span class=\"ansi-bold\">Dataset glue downloaded and prepared to /root/tensorflow_datasets/glue/mrpc/0.0.2. Subsequent calls will reuse this data.</span>\nINFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/0.0.2\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["train_dataset = glue_convert_examples_to_features(data['train'], teacher_tokenizer, max_length=config.max_seq_len, task='mrpc')\nvalid_dataset = glue_convert_examples_to_features(data['validation'], teacher_tokenizer, max_length=config.max_seq_len, task='mrpc')\ntrain_dataset = train_dataset.shuffle(100).batch(16).repeat(2)\nvalid_dataset = valid_dataset.batch(32)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["Training the student model ONLY"],"metadata":{}},{"cell_type":"markdown","source":["Training the knowledge distiller"],"metadata":{}},{"cell_type":"code","source":["# loss1 = ce_loss_fct_torch(torch.tensor([1.0,1.0]), torch.tensor([0.0, 0.0]), config)\n# loss2 = ce_loss_fct(tf.constant([1.0,1.0]), tf.constant([0.0,0.0]), config)\n# assert(loss1.numpy()==loss2.numpy())\n\nloss1 = mse_loss_fct_torch(torch.tensor([[1.0,1.0],[2.0,2.0]]), torch.tensor([[0.0,0.0],[1.0, 1.0]]))\nloss2 = mse_loss_fct(tf.constant([[1.0,1.0],[2.0,2.0]]), tf.constant([[0.0,0.0],[1.0, 1.0]]))\nassert(loss1.numpy()==loss2.numpy())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["import torch.nn.functional as F\nimport torch\n\ndef loss_fn_v2(teacher_logits, student_logits, targets, config):\n  loss_op_standard = standard_loss_fct(student_logits, targets, config)\n  mse_loss = mse_loss_fct(teacher_logits, student_logits)\n  return loss_op_standard + mse_loss\n\ndef loss_fn_v1(teacher_logits, student_logits, targets, config):\n  loss_op_standard = standard_loss_fct(student_logits, targets, config)\n  loss_op_soft = ce_loss_fct(student_logits, teacher_logits, config)\n  return loss_op_standard + loss_op_soft\n\ndef standard_loss_fct(student_logits, targets, config):\n  one_hot_targets = tf.one_hot(targets, config.num_classes, dtype=tf.float32)\n  loss_op_standard = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=student_logits, labels=one_hot_targets\n  ))\n  return loss_op_standard\n\ndef ce_loss_fct(student_logits, teacher_logits, config):\n  teacher_targets = tf.nn.softmax(tf.multiply(teacher_logits,  1.0 / config.distill_temperature))\n  loss_op_soft = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=tf.multiply(student_logits, 1.0 / config.distill_temperature), labels=tf.stop_gradient(teacher_targets)\n  ))\n  # scale soft target obj to match hard target obj. scale\n  loss_op_soft *= tf.square(config.distill_temperature)\n  return loss_op_soft\n\ndef ce_loss_fct_torch(student_logits, teacher_logits, config):\n  loss = torch.nn.KLDivLoss(reduction='batchmean')\n  return loss(F.log_softmax(student_logits/config.distill_temperature, dim=-1),\n              F.softmax(teacher_logits/config.distill_temperature, dim=-1))*(config.distill_temperature)**2\n\ndef mse_loss_fct(teacher_logits, student_logits):\n  return tf.reduce_mean(tf.keras.losses.MSE(teacher_logits, student_logits))\n\ndef mse_loss_fct_torch(teacher_logits, student_logits):\n  return torch.nn.MSELoss(reduction='mean')(teacher_logits, student_logits)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["def get_loss_acc(student, teacher, valid_dataset, config):\n  mean_loss = tf.keras.metrics.Mean()\n  acc = tf.keras.metrics.SparseCategoricalAccuracy()\n  for x, y in valid_dataset:\n    student_logits = student(x)[0]\n    teacher_logits = teacher(x)[0]\n    pred = tf.nn.softmax(student_logits)\n    loss = loss_fn_v1(teacher_logits, student_logits, y, config)\n    acc(y, pred)\n    mean_loss(loss)\n  return mean_loss.result().numpy(), acc.result().numpy()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["# optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate, epsilon=config.adam_epsilon, clipnorm=config.max_grad_norm)\n# ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=student)\n# manager = tf.train.CheckpointManager(ckpt, '/tmp/distil', max_to_keep=5)\n# ckpt = tf.train.Checkpoint(step=tf.Variable(1), opt=optimizer, net=student)\n# ckpt.restore('/dbfs/ml/judith/transformers/ckpts/ckpt-2').assert_consumed()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["%fs\nls dbfs:/ml/judith/transformers/distilbert/experiment3"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/ml/judith/transformers/distilbert/experiment3/config.json</td><td>config.json</td><td>188</td></tr></tbody></table></div>"]}}],"execution_count":30},{"cell_type":"code","source":["import os\n\n# setup directory\nsave_dir = \"/dbfs/ml/judith/transformers/distilbert/experiment3\"\nlocal_dir = \"/tmp/experiment3/\"\nif not os.path.exists(local_dir):\n  os.mkdir(local_dir)\n\nif not os.path.exists(save_dir):\n  os.mkdir(save_dir)\n\n# optimizer\nconfig.learning_rate = 5e-4\nconfig.save_pretrained(save_dir)\noptimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate, epsilon=config.adam_epsilon, clipnorm=config.max_grad_norm)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["train_loss = []\ntrain_acc = []\n\nfor epoch in range(config.epoch):\n  epoch_end_loss = tf.keras.metrics.Mean()\n  epoch_end_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n  \n  # Training loop - using batches of 16\n  for step, (x, y) in enumerate(train_dataset):\n    with tf.GradientTape() as tape:\n      student_logits = student(x)[0]\n      teacher_logits = teacher(x)[0]\n      targets = y\n      loss = loss_fn_v1(teacher_logits, student_logits, targets, config)\n    \n    # only optimize student weights\n    gradients = tape.gradient(loss, student.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, student.trainable_variables))\n\n    # logging\n    if step % 100 == 0:\n      print(step, float(loss))\n    \n    # log accuracy\n    pred = tf.nn.softmax(student_logits)\n    epoch_end_acc(targets, pred)\n    epoch_end_loss(loss)\n  \n  # End epoch\n  train_acc.append(epoch_end_acc.result())\n  train_loss.append(epoch_end_loss.result())\n  \n  val_loss, val_acc = get_loss_acc(student, teacher, valid_dataset, config)\n  print(\"epoch : {} training loss: {} training acc: {}\".format(epoch, epoch_end_loss.result(), epoch_end_acc.result()))\n  print(\"epoch : {} validation loss: {} validation acc: {}\".format(epoch, val_loss, val_acc))\n  \n  # save checkpoint\n#   ckpt.step.assign_add(1)\n#   save_path = manager.save()\n#   print(\"Saved checkpoint for epoch {} at {}\".format(int(ckpt.step), save_path))\n#   print(\"epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch, epoch_end_loss.result(), epoch_end_acc.result()))\n\n  # save model weights\n  student.save_weights(os.path.join(local_dir,\"ckpt-{}\".format(epoch)), save_format='tf')"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["get_loss_acc(student, teacher, valid_dataset, config)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: (3.4394732, 0.6838235)</div>"]}}],"execution_count":33},{"cell_type":"code","source":["for epoch in range(config.epoch):\n  student.load_weights(\"/dbfs/ml/judith/transformers/ckpts/{}\".format(epoch))\n  loss, acc = get_loss_acc(student, teacher, train_dataset, config)\n  print(\"epoch : {} training loss: {} training acc: {}\".format(epoch, loss, acc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">epoch : 0 training loss: 3.4508979320526123 training acc: 0.674481987953186\nepoch : 1 training loss: 3.446786642074585 training acc: 0.674481987953186\nepoch : 2 training loss: 3.4454026222229004 training acc: 0.674481987953186\nepoch : 3 training loss: 3.441863775253296 training acc: 0.674481987953186\nepoch : 4 training loss: 3.4411721229553223 training acc: 0.674481987953186\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["for epoch in range(config.epoch):\n  student.load_weights(\"/dbfs/ml/judith/transformers/ckpts/{}\".format(epoch))\n  loss, acc = get_loss_acc(student, teacher, valid_dataset, config)\n  print(\"epoch : {} validation loss: {} validation acc: {}\".format(epoch, loss, acc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">epoch : 0 validation loss: 3.4499192237854004 validation acc: 0.6838235259056091\nepoch : 1 validation loss: 3.4454843997955322 validation acc: 0.6838235259056091\nepoch : 2 validation loss: 3.4440395832061768 validation acc: 0.6838235259056091\nepoch : 3 validation loss: 3.439988613128662 validation acc: 0.6838235259056091\nepoch : 4 validation loss: 3.4394731521606445 validation acc: 0.6838235259056091\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["for epoch in range(config.epoch):\n  student.load_weights(\"/dbfs/ml/judith/transformers/ckpts/{}\".format(epoch))\n  train_acc = get_valid_acc(student, train_dataset)\n  acc = get_valid_acc(student, valid_dataset)\n  print(\"epoch : {} train acc: {} validation acc: {}\".format(epoch, train_acc.numpy(), acc.numpy()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">epoch : 0 train acc: 0.674481987953186 validation acc: 0.6838235259056091\nepoch : 1 train acc: 0.674481987953186 validation acc: 0.6838235259056091\nepoch : 2 train acc: 0.674481987953186 validation acc: 0.6838235259056091\nepoch : 3 train acc: 0.674481987953186 validation acc: 0.6838235259056091\nepoch : 4 train acc: 0.674481987953186 validation acc: 0.6838235259056091\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["res = get_valid_acc(student, valid_dataset)\nres.numpy()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: 0.6838235</div>"]}}],"execution_count":37},{"cell_type":"code","source":["%fs\ncp -r file:/tmp/distilbert dbfs:/ml/judith/transformers/ckpts"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res0: Boolean = true\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["tf.argmax(results,1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[54]: &lt;tf.Tensor: id=2586014, shape=(24,), dtype=int64, numpy=\narray([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1])&gt;</div>"]}}],"execution_count":39},{"cell_type":"code","source":["tf.equal(tf.argmax(results, 1), tf.argmax())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: array([[-0.60986143,  1.0837568 ],\n       [ 0.09118471,  0.29516476],\n       [-0.7158415 ,  1.1913157 ],\n       [-0.4526738 ,  0.923979  ],\n       [-0.19267556,  0.65840644],\n       [-0.65269977,  1.1091357 ],\n       [ 0.71593946, -0.49036485],\n       [-0.62001866,  1.0765138 ],\n       [-0.65391034,  1.1503623 ],\n       [-0.2535582 ,  0.72101456],\n       [-0.42134604,  0.87415594],\n       [-0.719673  ,  1.2054204 ],\n       [-0.6649697 ,  1.1418422 ],\n       [-0.37266234,  0.8350723 ],\n       [-0.68396103,  1.181153  ],\n       [-0.34383416,  0.80864   ],\n       [-0.4569165 ,  0.94713295],\n       [-0.08806867,  0.53173596],\n       [-0.7284867 ,  1.2087333 ],\n       [-0.12023775,  0.57294476],\n       [-0.51208216,  0.97944826],\n       [-0.06646109,  0.47441307],\n       [-0.13662477,  0.5703864 ],\n       [-0.4707438 ,  0.9563202 ],\n       [-0.54565   ,  1.0553306 ],\n       [-0.65720594,  1.1375569 ],\n       [-0.603665  ,  1.0736836 ],\n       [-0.5706943 ,  1.0548316 ],\n       [-0.63253826,  1.1077539 ],\n       [-0.17473526,  0.6080356 ],\n       [-0.5258696 ,  0.9823329 ],\n       [-0.6367127 ,  1.1030618 ],\n       [-0.6464472 ,  1.1340488 ],\n       [-0.47155175,  0.9452964 ],\n       [-0.47981796,  0.9446642 ],\n       [-0.16580467,  0.62852514],\n       [ 0.13576464,  0.26995686],\n       [-0.3330386 ,  0.79294926],\n       [-0.67616814,  1.1361644 ],\n       [-0.5728045 ,  1.0284945 ],\n       [-0.5234155 ,  1.0313827 ],\n       [-0.71388495,  1.1600287 ],\n       [-0.67785823,  1.1390435 ],\n       [-0.34962395,  0.80862415],\n       [-0.2661931 ,  0.7122902 ],\n       [-0.5598904 ,  1.0254445 ],\n       [-0.6257291 ,  1.1060236 ],\n       [-0.47577593,  0.9198599 ],\n       [-0.34090135,  0.79095286],\n       [ 0.04019816,  0.3601394 ],\n       [-0.17880383,  0.6337542 ],\n       [-0.4719053 ,  0.9582414 ],\n       [-0.36412588,  0.81866926],\n       [ 0.33677736,  0.00894536],\n       [-0.6666045 ,  1.1421952 ],\n       [-0.68127775,  1.151847  ],\n       [-0.5248226 ,  0.97841525],\n       [-0.61063206,  1.048671  ],\n       [-0.70198333,  1.1634849 ],\n       [ 0.18742082,  0.20412788],\n       [-0.46214527,  0.9319813 ],\n       [-0.10471676,  0.5197073 ],\n       [-0.5259552 ,  1.004858  ],\n       [-0.6098042 ,  1.0599213 ],\n       [-0.4391064 ,  0.8936264 ],\n       [-0.1867569 ,  0.59780186],\n       [ 0.01940855,  0.38897607],\n       [-0.6644772 ,  1.1325732 ],\n       [-0.69174916,  1.1506382 ],\n       [ 0.13589337,  0.2673158 ],\n       [-0.6700962 ,  1.153359  ],\n       [-0.27388388,  0.74286956],\n       [-0.49037316,  0.9955026 ],\n       [ 0.06454299,  0.32583514],\n       [-0.6437716 ,  1.1110007 ],\n       [-0.64400685,  1.1352906 ],\n       [-0.48827204,  0.94044757],\n       [ 0.3493447 , -0.01391271],\n       [-0.44950223,  0.9450929 ],\n       [-0.44175732,  0.89276075],\n       [-0.12980844,  0.58551854],\n       [-0.56955487,  1.0211033 ],\n       [-0.5057421 ,  0.9676329 ],\n       [-0.52656007,  1.0051538 ],\n       [-0.75315326,  1.2196054 ],\n       [-0.73955667,  1.1934521 ],\n       [-0.46626502,  0.92870414],\n       [-0.20918107,  0.6667271 ],\n       [-0.6871907 ,  1.1455532 ],\n       [ 0.19710787,  0.18170668],\n       [-0.53174716,  0.9748563 ],\n       [-0.54306877,  1.0390803 ],\n       [-0.00926425,  0.40115273],\n       [-0.6642691 ,  1.1283369 ],\n       [-0.09411409,  0.53803265],\n       [-0.3017078 ,  0.75204587],\n       [ 0.4829687 , -0.15538216],\n       [ 0.09240162,  0.28422883],\n       [-0.5689018 ,  1.0553023 ],\n       [ 0.03437992,  0.38740957],\n       [-0.6761581 ,  1.166359  ],\n       [ 0.3739927 , -0.0250047 ],\n       [-0.625628  ,  1.1148757 ],\n       [-0.40893525,  0.8901157 ],\n       [-0.70678365,  1.1496271 ],\n       [-0.5310745 ,  0.9906875 ],\n       [-0.7055363 ,  1.1751262 ],\n       [-0.7160511 ,  1.2080854 ],\n       [-0.47041994,  0.9091687 ],\n       [ 0.3139905 ,  0.05027173],\n       [-0.19564812,  0.6145728 ],\n       [-0.6886486 ,  1.1997702 ],\n       [ 0.09650204,  0.29227754],\n       [ 0.15494311,  0.22039104],\n       [-0.6474567 ,  1.1244891 ],\n       [-0.42002368,  0.88138753],\n       [ 0.06390077,  0.31207672],\n       [-0.6923533 ,  1.1554077 ],\n       [-0.40595224,  0.84243625],\n       [-0.57191527,  1.0365535 ],\n       [ 0.06131126,  0.37641776],\n       [-0.5390514 ,  1.0298933 ],\n       [-0.75057185,  1.2168492 ],\n       [-0.05449066,  0.45387274],\n       [-0.51358753,  0.990801  ],\n       [ 0.74454826, -0.52988833],\n       [-0.17847995,  0.60256094],\n       [-0.5359979 ,  1.0136193 ],\n       [-0.4672489 ,  0.95812005],\n       [-0.11980329,  0.5517218 ],\n       [-0.17644118,  0.6146549 ],\n       [-0.45917714,  0.9457082 ],\n       [-0.40235808,  0.8993072 ],\n       [-0.6301533 ,  1.116043  ],\n       [-0.07684531,  0.4793113 ],\n       [-0.6808449 ,  1.1424247 ],\n       [-0.13641942,  0.5501804 ],\n       [-0.45896402,  0.91506624],\n       [-0.5837547 ,  1.0716311 ],\n       [-0.6697946 ,  1.1628697 ],\n       [-0.63827807,  1.0947073 ],\n       [-0.6820466 ,  1.1554333 ],\n       [-0.7536713 ,  1.2073932 ],\n       [-0.4450441 ,  0.9564603 ],\n       [-0.76188827,  1.2229558 ],\n       [-0.7290037 ,  1.1908339 ],\n       [-0.6200871 ,  1.1089082 ],\n       [-0.6913718 ,  1.1488794 ],\n       [-0.72735995,  1.1903647 ],\n       [-0.48433974,  0.9285393 ],\n       [-0.57569927,  1.0387609 ],\n       [-0.45813528,  0.9079206 ],\n       [-0.2586142 ,  0.73831224],\n       [ 0.8386817 , -0.6555048 ],\n       [-0.25037408,  0.6763926 ],\n       [-0.5262398 ,  0.9749277 ],\n       [-0.40668178,  0.8904819 ],\n       [-0.25743005,  0.7086824 ],\n       [-0.58742553,  1.046126  ],\n       [ 0.02979179,  0.37410814],\n       [-0.49153686,  0.97149444],\n       [ 0.21300356,  0.18271379],\n       [-0.15207762,  0.61725646],\n       [-0.54420084,  1.0125548 ],\n       [-0.72624713,  1.1916704 ],\n       [-0.31672683,  0.7809374 ],\n       [-0.77034   ,  1.2147766 ],\n       [-0.35301325,  0.80647236],\n       [-0.51629835,  0.98016536],\n       [-0.5964029 ,  1.0594662 ],\n       [-0.26775992,  0.7036062 ],\n       [-0.6779986 ,  1.1768    ],\n       [-0.38766128,  0.8649642 ],\n       [-0.6294745 ,  1.1009499 ],\n       [-0.2545053 ,  0.7157417 ],\n       [-0.75748295,  1.2245206 ],\n       [-0.3858584 ,  0.8419607 ],\n       [ 0.09111194,  0.31491062],\n       [-0.65766716,  1.1308545 ],\n       [-0.7511802 ,  1.2098392 ],\n       [-0.70574725,  1.1621014 ],\n       [ 0.4905789 , -0.16605763],\n       [-0.37522107,  0.83049625],\n       [-0.30945036,  0.78328   ],\n       [ 0.66957355, -0.42293993],\n       [-0.6265417 ,  1.0765436 ],\n       [-0.70362866,  1.1749794 ],\n       [-0.42494744,  0.9225471 ],\n       [-0.5743515 ,  1.0291859 ],\n       [-0.5287475 ,  0.99993783],\n       [-0.10816612,  0.5384038 ],\n       [-0.60885805,  1.092441  ],\n       [-0.48700163,  0.9390087 ],\n       [-0.7065592 ,  1.164315  ],\n       [-0.5316934 ,  0.98641276],\n       [-0.22598645,  0.67814577],\n       [-0.20419982,  0.69318336],\n       [-0.7363611 ,  1.1906503 ],\n       [-0.44603088,  0.94387406],\n       [-0.6186008 ,  1.0993158 ],\n       [ 0.6292068 , -0.371192  ],\n       [-0.70041895,  1.1611817 ],\n       [-0.598578  ,  1.0830885 ],\n       [-0.39371154,  0.854546  ],\n       [-0.47708818,  0.95817727],\n       [-0.4641343 ,  0.9337197 ],\n       [-0.19881444,  0.6612907 ],\n       [-0.70258385,  1.1833097 ],\n       [ 0.01921667,  0.3561064 ],\n       [ 0.11157998,  0.28190488],\n       [-0.35099337,  0.7968624 ],\n       [-0.71550024,  1.1731924 ],\n       [-0.13178052,  0.58949375],\n       [-0.56681126,  1.036764  ],\n       [-0.5415267 ,  1.0014989 ],\n       [-0.3222458 ,  0.77354646],\n       [-0.6642209 ,  1.1230447 ],\n       [-0.53340435,  1.0110501 ],\n       [-0.6330969 ,  1.0914989 ],\n       [ 0.56151044, -0.25936398],\n       [-0.6942523 ,  1.1585346 ],\n       [-0.3750659 ,  0.8292242 ],\n       [-0.5960137 ,  1.0701213 ],\n       [-0.31011   ,  0.7871056 ],\n       [-0.46859556,  0.9233277 ],\n       [-0.570793  ,  1.0204974 ],\n       [-0.7536322 ,  1.2238233 ],\n       [-0.19901405,  0.6544528 ],\n       [-0.47050703,  0.9360265 ],\n       [-0.7130474 ,  1.2022015 ],\n       [-0.2538047 ,  0.71159613],\n       [ 0.80169016, -0.60169435],\n       [ 0.43450907, -0.10336939],\n       [-0.2076173 ,  0.66275483],\n       [-0.4422623 ,  0.9293045 ],\n       [-0.5166691 ,  0.98162806],\n       [-0.57484764,  1.0660498 ],\n       [-0.7513266 ,  1.2089288 ],\n       [-0.50487614,  0.9719872 ],\n       [-0.71118796,  1.173322  ],\n       [-0.57546866,  1.0684462 ],\n       [-0.6283702 ,  1.1175115 ],\n       [-0.58658844,  1.0667063 ],\n       [-0.58385247,  1.0782905 ],\n       [-0.5389265 ,  1.0050408 ],\n       [-0.51544124,  0.99332094],\n       [-0.51209885,  1.004359  ],\n       [-0.2550901 ,  0.7286719 ],\n       [-0.4772273 ,  0.9837064 ],\n       [-0.6537503 ,  1.1280915 ],\n       [-0.30342495,  0.74890363],\n       [-0.40434945,  0.8836471 ],\n       [-0.5087101 ,  0.9803641 ],\n       [-0.02081643,  0.45192793],\n       [-0.58381313,  1.0773028 ],\n       [-0.02193618,  0.43172184],\n       [ 0.06487905,  0.342425  ],\n       [-0.6019474 ,  1.086414  ],\n       [ 0.71576554, -0.48539412],\n       [-0.3185226 ,  0.7690384 ],\n       [ 0.715437  , -0.4748954 ],\n       [-0.43710402,  0.8923494 ],\n       [-0.4420778 ,  0.89611924],\n       [-0.17499311,  0.6131722 ],\n       [-0.3808338 ,  0.8651877 ],\n       [ 0.8345343 , -0.64595634],\n       [-0.7561729 ,  1.2110023 ],\n       [-0.64039826,  1.1267611 ],\n       [ 0.16167848,  0.24437411],\n       [-0.18057244,  0.619621  ],\n       [-0.4287597 ,  0.89340407],\n       [-0.6111456 ,  1.064643  ],\n       [-0.65388566,  1.1264155 ],\n       [-0.54367846,  1.0270011 ],\n       [-0.6600073 ,  1.1550134 ],\n       [-0.2699703 ,  0.7047866 ],\n       [-0.46392974,  0.90722036],\n       [-0.14275058,  0.5682766 ],\n       [-0.68987715,  1.1683196 ],\n       [-0.53109497,  1.0268342 ],\n       [ 0.08958089,  0.31101853],\n       [-0.6917605 ,  1.1946371 ],\n       [-0.53175837,  0.99634635],\n       [-0.19837345,  0.6444692 ],\n       [-0.695307  ,  1.1569086 ],\n       [-0.42728764,  0.91780955],\n       [-0.67273605,  1.1330677 ],\n       [-0.314269  ,  0.76416445],\n       [-0.49649456,  0.94131494],\n       [-0.62442356,  1.0889798 ],\n       [-0.76593   ,  1.2200412 ],\n       [-0.42914736,  0.90787053],\n       [-0.6308196 ,  1.1066313 ],\n       [-0.51893884,  0.97639704],\n       [-0.47577772,  0.9447531 ],\n       [-0.73090917,  1.2023364 ],\n       [-0.6490901 ,  1.1176956 ],\n       [-0.42115763,  0.8996933 ],\n       [-0.7594249 ,  1.2258865 ],\n       [-0.46176562,  0.94730985],\n       [-0.741211  ,  1.2305887 ],\n       [ 0.17242752,  0.20427926],\n       [-0.69443136,  1.159434  ],\n       [-0.4564414 ,  0.94977903],\n       [-0.66133696,  1.111004  ],\n       [-0.37637663,  0.84005636],\n       [-0.47892952,  0.9281695 ],\n       [-0.4598931 ,  0.9195093 ],\n       [ 0.33016646,  0.02715523],\n       [-0.50684726,  0.96186495],\n       [-0.5790086 ,  1.0473347 ],\n       [-0.6998757 ,  1.1679543 ],\n       [-0.60222566,  1.0543243 ],\n       [ 0.24767976,  0.12272455],\n       [-0.68742365,  1.1760901 ],\n       [-0.42944142,  0.91699153],\n       [-0.7651931 ,  1.2259684 ],\n       [-0.6280719 ,  1.1060568 ],\n       [-0.27877986,  0.7402421 ],\n       [-0.6399647 ,  1.1178888 ],\n       [-0.7259866 ,  1.2100884 ],\n       [-0.5885512 ,  1.0490435 ],\n       [-0.5020841 ,  0.9603481 ],\n       [-0.68009263,  1.1382908 ],\n       [-0.61351657,  1.0826352 ],\n       [-0.5624586 ,  1.0552789 ],\n       [ 0.7754463 , -0.5672282 ],\n       [ 0.6278446 , -0.36399478],\n       [-0.49455464,  0.98034334],\n       [-0.5321611 ,  1.0085567 ],\n       [-0.5777618 ,  1.03566   ],\n       [-0.5316357 ,  1.0173811 ],\n       [-0.46055445,  0.9087054 ],\n       [-0.58500004,  1.0694475 ],\n       [-0.7327889 ,  1.1974117 ],\n       [ 0.04488435,  0.36559463],\n       [-0.4019766 ,  0.86226964],\n       [-0.7846899 ,  1.2360284 ],\n       [-0.47570348,  0.9559118 ],\n       [ 0.09463584,  0.29168952],\n       [-0.28423104,  0.74656105],\n       [-0.6105558 ,  1.0874923 ],\n       [-0.35518038,  0.80786705],\n       [-0.59832835,  1.0706549 ],\n       [-0.63569444,  1.1319909 ],\n       [-0.0762224 ,  0.5035711 ],\n       [ 0.46077883, -0.12477852],\n       [-0.5112439 ,  1.0086899 ],\n       [ 0.33127546,  0.02014153],\n       [ 0.10888336,  0.29310945],\n       [-0.57670975,  1.037085  ],\n       [-0.17108533,  0.61969966],\n       [-0.39024916,  0.84282535],\n       [-0.00173227,  0.41229367],\n       [-0.46004316,  0.9343058 ],\n       [-0.28406757,  0.7406981 ],\n       [-0.40458682,  0.87880623],\n       [-0.46247503,  0.9314417 ],\n       [-0.35781664,  0.8163434 ],\n       [-0.45597035,  0.9468559 ],\n       [-0.66349053,  1.1259834 ],\n       [-0.6862367 ,  1.1445678 ],\n       [-0.51305956,  1.0236895 ],\n       [-0.6694762 ,  1.1217036 ],\n       [-0.06652283,  0.49290916],\n       [-0.15877895,  0.58021516],\n       [-0.40750262,  0.8857519 ],\n       [-0.064703  ,  0.4657713 ],\n       [-0.6175363 ,  1.1073942 ],\n       [-0.25684583,  0.7570202 ],\n       [-0.72920495,  1.2009436 ],\n       [-0.12385961,  0.535716  ],\n       [-0.21905355,  0.65599644],\n       [-0.54693884,  1.0154436 ],\n       [-0.41733435,  0.8756955 ],\n       [-0.68600655,  1.1810347 ],\n       [-0.5377482 ,  1.0218517 ],\n       [-0.04866819,  0.44129387],\n       [-0.22998099,  0.6753974 ],\n       [-0.12660873,  0.51717275],\n       [-0.3874932 ,  0.8635892 ],\n       [-0.13106196,  0.5411505 ],\n       [-0.14800578,  0.61611   ],\n       [-0.62508535,  1.1139387 ],\n       [-0.6181559 ,  1.095306  ],\n       [-0.14507397,  0.5861645 ],\n       [-0.26528   ,  0.7203165 ],\n       [ 0.5593344 , -0.26769775],\n       [-0.07207283,  0.46251655],\n       [-0.13189554,  0.55697227],\n       [-0.4228104 ,  0.883703  ],\n       [-0.26229292,  0.7089725 ],\n       [-0.33670288,  0.83267665],\n       [-0.01852397,  0.44646728],\n       [-0.10542403,  0.53322965],\n       [-0.5683286 ,  1.0394784 ],\n       [-0.46776813,  0.97743857],\n       [-0.7426105 ,  1.1880633 ],\n       [-0.5211363 ,  0.9976792 ],\n       [-0.15981065,  0.61718774],\n       [-0.49538803,  0.9780677 ],\n       [ 0.12010587,  0.2941149 ],\n       [-0.6170561 ,  1.1113406 ],\n       [ 0.1107824 ,  0.26354972],\n       [-0.7458305 ,  1.2067152 ],\n       [-0.53781396,  1.029937  ],\n       [-0.05016173,  0.4704274 ],\n       [-0.7429669 ,  1.215593  ]], dtype=float32)</div>"]}}],"execution_count":40},{"cell_type":"code","source":["input_words = [\"dogs are on the ground\", \"cats are in the cloud\"]\ninput_word_ids = tf.constant([teacher_tokenizer.encode(text) for text in input_words])\ntargets = tf.constant([1, 0])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"code","source":["teacher_logits = teacher(input_word_ids)\nstudent_logits = student(input_word_ids)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["loss_fn(teacher_logits, student_logits, targets, config)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[61]: &lt;tf.Tensor: id=71154, shape=(), dtype=float32, numpy=0.6950183&gt;</div>"]}}],"execution_count":43},{"cell_type":"code","source":["amax_seq_length = 128  # Your choice here.\ninput_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                       name=\"input_word_ids\")\nattention_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                   name=\"attention_mask\")\ntoken_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                    name=\"token_type_ids\")\nbert_layer = hub.KerasLayer(\"/dbfs/ml/smrt-hub/bert-base-uncased/1\",\n                            trainable=True)\nsequence_output, pooled_output = bert_layer([input_word_ids, attention_mask, token_type_ids])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["dir(bert_layer.resolved_object)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: [&#39;__call__&#39;,\n &#39;__class__&#39;,\n &#39;__delattr__&#39;,\n &#39;__dict__&#39;,\n &#39;__dir__&#39;,\n &#39;__doc__&#39;,\n &#39;__eq__&#39;,\n &#39;__format__&#39;,\n &#39;__ge__&#39;,\n &#39;__getattribute__&#39;,\n &#39;__gt__&#39;,\n &#39;__hash__&#39;,\n &#39;__init__&#39;,\n &#39;__init_subclass__&#39;,\n &#39;__le__&#39;,\n &#39;__lt__&#39;,\n &#39;__module__&#39;,\n &#39;__ne__&#39;,\n &#39;__new__&#39;,\n &#39;__reduce__&#39;,\n &#39;__reduce_ex__&#39;,\n &#39;__repr__&#39;,\n &#39;__setattr__&#39;,\n &#39;__sizeof__&#39;,\n &#39;__str__&#39;,\n &#39;__subclasshook__&#39;,\n &#39;__weakref__&#39;,\n &#39;_add_variable_with_custom_getter&#39;,\n &#39;_checkpoint_dependencies&#39;,\n &#39;_default_save_signature&#39;,\n &#39;_deferred_dependencies&#39;,\n &#39;_gather_saveables_for_checkpoint&#39;,\n &#39;_handle_deferred_dependencies&#39;,\n &#39;_is_hub_module_v1&#39;,\n &#39;_list_extra_dependencies_for_serialization&#39;,\n &#39;_list_functions_for_serialization&#39;,\n &#39;_lookup_dependency&#39;,\n &#39;_maybe_initialize_trackable&#39;,\n &#39;_name_based_attribute_restore&#39;,\n &#39;_name_based_restores&#39;,\n &#39;_no_dependency&#39;,\n &#39;_object_identifier&#39;,\n &#39;_preload_simple_restoration&#39;,\n &#39;_restore_from_checkpoint_position&#39;,\n &#39;_self_name_based_restores&#39;,\n &#39;_self_setattr_tracking&#39;,\n &#39;_self_unconditional_checkpoint_dependencies&#39;,\n &#39;_self_unconditional_deferred_dependencies&#39;,\n &#39;_self_unconditional_dependency_names&#39;,\n &#39;_self_update_uid&#39;,\n &#39;_setattr_tracking&#39;,\n &#39;_single_restoration_from_checkpoint_position&#39;,\n &#39;_track_trackable&#39;,\n &#39;_tracking_metadata&#39;,\n &#39;_unconditional_checkpoint_dependencies&#39;,\n &#39;_unconditional_dependency_names&#39;,\n &#39;_update_uid&#39;,\n &#39;call_and_return_all_conditional_losses&#39;,\n &#39;keras_api&#39;,\n &#39;layer-0&#39;,\n &#39;layer-1&#39;,\n &#39;layer-2&#39;,\n &#39;layer-3&#39;,\n &#39;layer-4&#39;,\n &#39;layer-5&#39;,\n &#39;layer_with_weights-0&#39;,\n &#39;regularization_losses&#39;,\n &#39;signatures&#39;,\n &#39;tensorflow_git_version&#39;,\n &#39;tensorflow_version&#39;,\n &#39;trainable_variables&#39;,\n &#39;variables&#39;]</div>"]}}],"execution_count":45},{"cell_type":"code","source":["vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["# Prepare dataset for GLUE as a tf.data.Dataset instance\n\ndata = tensorflow_datasets.load('glue/mrpc')\n\n# train_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\n# valid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\n# train_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\n# valid_dataset = valid_dataset.batch(64)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">INFO:absl:Overwrite dataset info from restored data version.\nINFO:absl:Reusing dataset glue (/root/tensorflow_datasets/glue/mrpc/0.0.2)\nINFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/0.0.2\n</div>"]}}],"execution_count":47},{"cell_type":"markdown","source":["Train DistillBert"],"metadata":{}},{"cell_type":"code","source":["student_config_class, student_model_class, student_tokenizer_class = DistilBertConfig, TFDistilBertForSequenceClassification, DistilBertTokenizer\nteacher_config_class, teacher_model_class, teacher_tokenizer_class = BertConfig, TFBertForSequenceClassification, BertTokenizer"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":49},{"cell_type":"code","source":["tokenizer = teacher_tokenizer_class.from_pretrained('bert-base-uncased')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/231508 [00:00&lt;?, ?B/s]\r 15%|█▌        | 34816/231508 [00:00&lt;00:00, 244937.24B/s]\r 75%|███████▌  | 174080/231508 [00:00&lt;00:00, 321776.45B/s]\r100%|██████████| 231508/231508 [00:00&lt;00:00, 888860.24B/s]\n</div>"]}}],"execution_count":50},{"cell_type":"code","source":["student_config = {\n\t\"activation\": \"gelu\",\n\t\"attention_dropout\": 0.1,\n\t\"dim\": 768,\n\t\"dropout\": 0.1,\n\t\"hidden_dim\": 3072,\n\t\"initializer_range\": 0.02,\n\t\"max_position_embeddings\": 512,\n\t\"n_heads\": 12,\n\t\"n_layers\": 6,\n\t\"sinusoidal_pos_embds\": true,\n\t\"tie_weights_\": true,\n\t\"vocab_size\": 30522\n  }"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-145069&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>         <span class=\"ansi-blue-fg\">&#34;n_heads&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>         <span class=\"ansi-blue-fg\">&#34;n_layers&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-cyan-fg\">6</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 11</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-blue-fg\">&#34;sinusoidal_pos_embds&#34;</span><span class=\"ansi-blue-fg\">:</span> true<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span>         <span class=\"ansi-blue-fg\">&#34;tie_weights_&#34;</span><span class=\"ansi-blue-fg\">:</span> true<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>         <span class=\"ansi-blue-fg\">&#34;vocab_size&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-cyan-fg\">30522</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;true&#39; is not defined</div>"]}}],"execution_count":51},{"cell_type":"code","source":["# Student\nstu_architecture_config = student_config_class.from_pretrained(\"/dbfs/ml/judith/transformers/distilbert-base-uncased.json\")\nstu_architecture_config.sinusoidal_pos_embds = False\nstudent = student_model_class(stu_architecture_config)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["teacher = teacher_model_class.from_pretrained(\"bert-base-uncased\")#, output_hidden_states=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-145070&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>teacher <span class=\"ansi-blue-fg\">=</span> teacher_model_class<span class=\"ansi-blue-fg\">.</span>from_pretrained<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;bert-base-uncased&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">#, output_hidden_states=True)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;teacher_model_class&#39; is not defined</div>"]}}],"execution_count":53},{"cell_type":"markdown","source":["Evaluation using fine-tuned model"],"metadata":{}},{"cell_type":"code","source":["# Load dataset, tokenizer, model from pretrained model/vocabulary\ntokenizer = DistilBertTokenizer.from_pretrained('/dbfs/ml/judith/transformers/mrpc/2')\nmodel = TFDistilBertForSequenceClassification.from_pretrained('/dbfs/ml/judith/transformers/mrpc/2')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":55},{"cell_type":"code","source":["results = model.predict(valid_dataset)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"code","source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n# tf.config.experimental.set_visible_devices(gpus[0], 'GPU')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":57},{"cell_type":"code","source":["# Load dataset, tokenizer, model from pretrained model/vocabulary\nteacher_tokenizer = BertTokenizer.from_pretrained('/dbfs/ml/judith/transformers/mrpc/1')\nteacher_model = TFBertForSequenceClassification.from_pretrained('/dbfs/ml/judith/transformers/mrpc/1')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["results = teacher_model.predict(valid_dataset)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"markdown","source":["Prepare Dataset from MRPC"],"metadata":{}},{"cell_type":"code","source":["data = tensorflow_datasets.load('glue/mrpc')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">INFO:absl:Load pre-computed datasetinfo (eg: splits) from bucket.\nINFO:absl:Loading info from GCS for glue/mrpc/0.0.2\nINFO:absl:Generating dataset glue (/root/tensorflow_datasets/glue/mrpc/0.0.2)\n<span class=\"ansi-bold\">Downloading and preparing dataset glue (1.43 MiB) to /root/tensorflow_datasets/glue/mrpc/0.0.2...</span>\n\rDl Completed...: 0 url [00:00, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&amp;token=ec5c0836-31d5-48f4-b431-7480817f1adc into /root/tensorflow_datasets/downloads/fire.goog.com_v0_b_mtl-sent-repr.apps.com_o_2FjSIMlCiqs1QSmIykr4IRPnEHjPuGwAz5i40v8K9U0Z8.tsvalt=media&amp;token=ec5c0836-31d5-48f4-b431-7480817f1adc.tmp.24178278854045c4813278abb8592eec...\n\rDl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt into /root/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_trainfGxPZuQWGBti4Tbd1YNOwQr-OqxPejJ7gcp0Al6mlSk.txt.tmp.09661eca187543a1842a1793db0336ef...\n\rDl Completed...:   0%|          | 0/2 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt into /root/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_test0PdekMcyqYR-w4Rx_d7OTryq0J3RlYRn4rAMajy9Mak.txt.tmp.3ae4ea2992c74b1888bbb6c9ea6f40a9...\n\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  2.18 url/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  2.18 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  67%|██████▋   | 2/3 [00:00&lt;00:00,  2.18 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  67%|██████▋   | 2/3 [00:00&lt;00:00,  2.18 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...: 100%|██████████| 3/3 [00:00&lt;00:00,  2.77 url/s]\rDl Completed...: 100%|██████████| 3/3 [00:00&lt;00:00,  2.77 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\nINFO:absl:Generating split train\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r257 examples [00:00, 2568.45 examples/s]\r506 examples [00:00, 2544.35 examples/s]\r768 examples [00:00, 2565.91 examples/s]\r1029 examples [00:00, 2577.93 examples/s]\r1292 examples [00:00, 2591.47 examples/s]\r1556 examples [00:00, 2603.95 examples/s]\r1805 examples [00:00, 2566.62 examples/s]\r2066 examples [00:00, 2578.02 examples/s]\r2324 examples [00:00, 2576.49 examples/s]\r2584 examples [00:01, 2581.04 examples/s]\r2846 examples [00:01, 2592.02 examples/s]\r3101 examples [00:01, 2534.43 examples/s]\r3364 examples [00:01, 2560.35 examples/s]\r3637 examples [00:01, 2607.71 examples/s]\r                                         \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\n\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/3668 [00:00&lt;?, ? examples/s]\n\r                                                           \r                                                       \rINFO:absl:Generating split validation\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r157 examples [00:00, 1555.73 examples/s]\r299 examples [00:00, 1504.71 examples/s]\r                                        \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/408 [00:00&lt;?, ? examples/s]\n\r                                                          \r                                                       \rINFO:absl:Generating split test\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r289 examples [00:00, 2888.79 examples/s]\r577 examples [00:00, 2883.38 examples/s]\r875 examples [00:00, 2910.70 examples/s]\r1149 examples [00:00, 2856.61 examples/s]\r1435 examples [00:00, 2857.49 examples/s]\r1719 examples [00:00, 2852.06 examples/s]\r                                         \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/1725 [00:00&lt;?, ? examples/s]\n\r                                                           \r                                                       \rINFO:absl:Skipping computing stats for mode ComputeStatsMode.AUTO.\n<span class=\"ansi-bold\">Dataset glue downloaded and prepared to /root/tensorflow_datasets/glue/mrpc/0.0.2. Subsequent calls will reuse this data.</span>\nINFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/0.0.2\n</div>"]}}],"execution_count":61},{"cell_type":"code","source":["# Prepare dataset for GLUE as a tf.data.Dataset instance\ntrain_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\nvalid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\ntrain_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\nvalid_dataset = valid_dataset.batch(64)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":62},{"cell_type":"markdown","source":["DistillBert for MRPC"],"metadata":{}},{"cell_type":"code","source":["# Load dataset, tokenizer, model from pretrained model/vocabulary\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/231508 [00:00&lt;?, ?B/s]\r 15%|█▌        | 34816/231508 [00:00&lt;00:00, 220780.88B/s]\r 97%|█████████▋| 225280/231508 [00:00&lt;00:00, 292349.73B/s]\r100%|██████████| 231508/231508 [00:00&lt;00:00, 727939.27B/s]\n\r  0%|          | 0/492 [00:00&lt;?, ?B/s]\r100%|██████████| 492/492 [00:00&lt;00:00, 417563.25B/s]\n\r  0%|          | 0/363423424 [00:00&lt;?, ?B/s]\r  0%|          | 52224/363423424 [00:00&lt;17:58, 336936.35B/s]\r  0%|          | 261120/363423424 [00:00&lt;13:55, 434462.90B/s]\r  0%|          | 940032/363423424 [00:00&lt;10:03, 600316.42B/s]\r  1%|          | 2228224/363423424 [00:00&lt;07:10, 839122.67B/s]\r  1%|▏         | 4753408/363423424 [00:00&lt;05:04, 1178015.86B/s]\r  2%|▏         | 7047168/363423424 [00:00&lt;03:36, 1642903.68B/s]\r  3%|▎         | 9553920/363423424 [00:00&lt;02:36, 2268326.95B/s]\r  3%|▎         | 11847680/363423424 [00:01&lt;01:53, 3095521.11B/s]\r  4%|▍         | 14370816/363423424 [00:01&lt;01:24, 4152717.39B/s]\r  5%|▍         | 16664576/363423424 [00:01&lt;01:03, 5463848.69B/s]\r  5%|▌         | 19171328/363423424 [00:01&lt;00:49, 6998458.41B/s]\r  6%|▌         | 21465088/363423424 [00:01&lt;00:39, 8735442.93B/s]\r  7%|▋         | 23988224/363423424 [00:01&lt;00:32, 10546369.10B/s]\r  7%|▋         | 26265600/363423424 [00:01&lt;00:27, 12350809.82B/s]\r  8%|▊         | 28788736/363423424 [00:01&lt;00:23, 14017607.25B/s]\r  9%|▊         | 31082496/363423424 [00:01&lt;00:21, 15522485.79B/s]\r  9%|▉         | 33589248/363423424 [00:02&lt;00:19, 16713664.95B/s]\r 10%|▉         | 35883008/363423424 [00:02&lt;00:18, 17736393.18B/s]\r 11%|█         | 38406144/363423424 [00:02&lt;00:17, 18483475.91B/s]\r 11%|█         | 40683520/363423424 [00:02&lt;00:16, 19057897.65B/s]\r 12%|█▏        | 43206656/363423424 [00:02&lt;00:16, 19460571.69B/s]\r 13%|█▎        | 45500416/363423424 [00:02&lt;00:16, 19801888.89B/s]\r 13%|█▎        | 48023552/363423424 [00:02&lt;00:15, 20009298.13B/s]\r 14%|█▍        | 50300928/363423424 [00:02&lt;00:15, 20164280.69B/s]\r 15%|█▍        | 52824064/363423424 [00:03&lt;00:15, 20260334.47B/s]\r 15%|█▌        | 55101440/363423424 [00:03&lt;00:15, 20346319.38B/s]\r 16%|█▌        | 57624576/363423424 [00:03&lt;00:15, 20377151.79B/s]\r 16%|█▋        | 59918336/363423424 [00:03&lt;00:14, 20492481.26B/s]\r 17%|█▋        | 62425088/363423424 [00:03&lt;00:14, 20440909.39B/s]\r 18%|█▊        | 64718848/363423424 [00:03&lt;00:14, 20516868.83B/s]\r 19%|█▊        | 67241984/363423424 [00:03&lt;00:14, 20497004.12B/s]\r 19%|█▉        | 69535744/363423424 [00:03&lt;00:14, 20571137.39B/s]\r 20%|█▉        | 72042496/363423424 [00:03&lt;00:14, 20496959.05B/s]\r 20%|██        | 74094592/363423424 [00:04&lt;00:16, 17249508.55B/s]\r 21%|██        | 76269568/363423424 [00:04&lt;00:17, 16272672.87B/s]\r 22%|██▏       | 78702592/363423424 [00:04&lt;00:15, 18067320.87B/s]\r 22%|██▏       | 80623616/363423424 [00:04&lt;00:17, 16416408.91B/s]\r 23%|██▎       | 83249152/363423424 [00:04&lt;00:16, 16787156.87B/s]\r 24%|██▎       | 85994496/363423424 [00:04&lt;00:14, 19001206.78B/s]\r 24%|██▍       | 88048640/363423424 [00:04&lt;00:15, 17477132.78B/s]\r 25%|██▍       | 90687488/363423424 [00:05&lt;00:15, 17494744.88B/s]\r 26%|██▌       | 93325312/363423424 [00:05&lt;00:13, 19460782.75B/s]\r 26%|██▋       | 95406080/363423424 [00:05&lt;00:15, 17620233.75B/s]\r 27%|██▋       | 97716224/363423424 [00:05&lt;00:15, 17038840.59B/s]\r 28%|██▊       | 100611072/363423424 [00:05&lt;00:13, 19437611.06B/s]\r 28%|██▊       | 102737920/363423424 [00:05&lt;00:14, 17788214.33B/s]\r 29%|██▉       | 104925184/363423424 [00:05&lt;00:15, 16808490.08B/s]\r 30%|██▉       | 107448320/363423424 [00:05&lt;00:13, 18678901.05B/s]\r 30%|███       | 109465600/363423424 [00:06&lt;00:14, 16968328.78B/s]\r 31%|███       | 111986688/363423424 [00:06&lt;00:14, 17043446.53B/s]\r 32%|███▏      | 114722816/363423424 [00:06&lt;00:14, 17195629.44B/s]\r 32%|███▏      | 117147648/363423424 [00:06&lt;00:13, 18838692.73B/s]\r 33%|███▎      | 119126016/363423424 [00:06&lt;00:14, 17185419.07B/s]\r 33%|███▎      | 120938496/363423424 [00:06&lt;00:14, 16726500.91B/s]\r 34%|███▍      | 122680320/363423424 [00:06&lt;00:15, 15226202.63B/s]\r 34%|███▍      | 124749824/363423424 [00:06&lt;00:15, 15182215.24B/s]\r 35%|███▌      | 127390720/363423424 [00:07&lt;00:13, 17401365.39B/s]\r 36%|███▌      | 129282048/363423424 [00:07&lt;00:14, 16033004.13B/s]\r 36%|███▋      | 131958784/363423424 [00:07&lt;00:13, 17471932.77B/s]\r 37%|███▋      | 133833728/363423424 [00:07&lt;00:13, 17206767.56B/s]\r 38%|███▊      | 136513536/363423424 [00:07&lt;00:12, 18425655.47B/s]\r 38%|███▊      | 138443776/363423424 [00:07&lt;00:12, 18285861.94B/s]\r 39%|███▊      | 140626944/363423424 [00:07&lt;00:11, 19221595.35B/s]\r 39%|███▉      | 142837760/363423424 [00:07&lt;00:11, 19763062.98B/s]\r 40%|███▉      | 144857088/363423424 [00:08&lt;00:11, 19478640.75B/s]\r 41%|████      | 147638272/363423424 [00:08&lt;00:10, 20163305.66B/s]\r 41%|████      | 149683200/363423424 [00:08&lt;00:10, 19786919.12B/s]\r 42%|████▏     | 152455168/363423424 [00:08&lt;00:10, 20387956.61B/s]\r 43%|████▎     | 154513408/363423424 [00:08&lt;00:10, 19949369.48B/s]\r 43%|████▎     | 157255680/363423424 [00:08&lt;00:10, 20486194.73B/s]\r 44%|████▍     | 159319040/363423424 [00:08&lt;00:10, 20048584.04B/s]\r 45%|████▍     | 162056192/363423424 [00:08&lt;00:09, 20523204.76B/s]\r 45%|████▌     | 164120576/363423424 [00:08&lt;00:09, 20084136.26B/s]\r 46%|████▌     | 166873088/363423424 [00:09&lt;00:09, 20581050.20B/s]\r 46%|████▋     | 168941568/363423424 [00:09&lt;00:09, 20073463.55B/s]\r 47%|████▋     | 171083776/363423424 [00:09&lt;00:10, 17542160.03B/s]\r 48%|████▊     | 173033472/363423424 [00:09&lt;00:12, 15546454.17B/s]\r 48%|████▊     | 175196160/363423424 [00:09&lt;00:12, 15020447.66B/s]\r 49%|████▊     | 176785408/363423424 [00:09&lt;00:14, 13196026.32B/s]\r 49%|████▉     | 178391040/363423424 [00:09&lt;00:15, 12165426.74B/s]\r 50%|████▉     | 180029440/363423424 [00:10&lt;00:15, 11616580.49B/s]\r 50%|████▉     | 181684224/363423424 [00:10&lt;00:16, 11294664.99B/s]\r 50%|█████     | 183371776/363423424 [00:10&lt;00:16, 11141757.23B/s]\r 51%|█████     | 184913920/363423424 [00:10&lt;00:14, 12153465.24B/s]\r 51%|█████     | 186178560/363423424 [00:10&lt;00:16, 11010445.84B/s]\r 52%|█████▏    | 187648000/363423424 [00:10&lt;00:16, 10623443.72B/s]\r 52%|█████▏    | 189384704/363423424 [00:10&lt;00:16, 10771377.44B/s]\r 53%|█████▎    | 191137792/363423424 [00:11&lt;00:15, 10908435.86B/s]\r 53%|█████▎    | 192907264/363423424 [00:11&lt;00:15, 11031342.05B/s]\r 54%|█████▎    | 194676736/363423424 [00:11&lt;00:15, 11129942.59B/s]\r 54%|█████▍    | 196478976/363423424 [00:11&lt;00:14, 11245575.85B/s]\r 55%|█████▍    | 198281216/363423424 [00:11&lt;00:14, 11342885.33B/s]\r 55%|█████▌    | 200099840/363423424 [00:11&lt;00:14, 11434962.19B/s]\r 56%|█████▌    | 201918464/363423424 [00:12&lt;00:14, 11506790.18B/s]\r 56%|█████▌    | 203753472/363423424 [00:12&lt;00:13, 11582422.75B/s]\r 57%|█████▋    | 205588480/363423424 [00:12&lt;00:12, 12173369.49B/s]\r 57%|█████▋    | 206816256/363423424 [00:12&lt;00:13, 11941292.65B/s]\r 57%|█████▋    | 208373760/363423424 [00:12&lt;00:12, 12042200.91B/s]\r 58%|█████▊    | 209584128/363423424 [00:12&lt;00:13, 11813707.36B/s]\r 58%|█████▊    | 211159040/363423424 [00:12&lt;00:12, 11993948.17B/s]\r 58%|█████▊    | 212363264/363423424 [00:12&lt;00:12, 11677190.78B/s]\r 59%|█████▉    | 213977088/363423424 [00:13&lt;00:12, 12035928.01B/s]\r 59%|█████▉    | 215187456/363423424 [00:13&lt;00:12, 11716877.74B/s]\r 60%|█████▉    | 216795136/363423424 [00:13&lt;00:12, 12058665.44B/s]\r 60%|█████▉    | 218008576/363423424 [00:13&lt;00:12, 11782827.33B/s]\r 60%|██████    | 219629568/363423424 [00:13&lt;00:11, 12097546.45B/s]\r 61%|██████    | 220846080/363423424 [00:13&lt;00:12, 11830059.25B/s]\r 61%|██████    | 222480384/363423424 [00:13&lt;00:11, 12154797.67B/s]\r 62%|██████▏   | 223703040/363423424 [00:13&lt;00:11, 11864105.55B/s]\r 62%|██████▏   | 225331200/363423424 [00:13&lt;00:11, 12180155.52B/s]\r 62%|██████▏   | 226555904/363423424 [00:14&lt;00:11, 11901241.69B/s]\r 63%|██████▎   | 228132864/363423424 [00:14&lt;00:12, 11131736.23B/s]\r 63%|██████▎   | 229771264/363423424 [00:14&lt;00:11, 11826775.99B/s]\r 64%|██████▎   | 230976512/363423424 [00:14&lt;00:11, 11277210.20B/s]\r 64%|██████▍   | 232125440/363423424 [00:14&lt;00:13, 9931211.01B/s] \r 64%|██████▍   | 233162752/363423424 [00:14&lt;00:13, 9408724.87B/s]\r 64%|██████▍   | 234140672/363423424 [00:14&lt;00:13, 9285059.12B/s]\r 65%|██████▍   | 235276288/363423424 [00:15&lt;00:13, 9210353.47B/s]\r 65%|██████▍   | 236216320/363423424 [00:15&lt;00:14, 9060741.76B/s]\r 65%|██████▌   | 237406208/363423424 [00:15&lt;00:13, 9165622.90B/s]\r 66%|██████▌   | 238332928/363423424 [00:15&lt;00:13, 8979021.14B/s]\r 66%|██████▌   | 239585280/363423424 [00:15&lt;00:13, 9250921.23B/s]\r 66%|██████▌   | 240518144/363423424 [00:15&lt;00:13, 9050266.71B/s]\r 67%|██████▋   | 241780736/363423424 [00:15&lt;00:13, 9326569.08B/s]\r 67%|██████▋   | 242720768/363423424 [00:15&lt;00:13, 9007259.86B/s]\r 67%|██████▋   | 244025344/363423424 [00:15&lt;00:12, 9469569.66B/s]\r 67%|██████▋   | 244983808/363423424 [00:16&lt;00:12, 9143576.12B/s]\r 68%|██████▊   | 246286336/363423424 [00:16&lt;00:12, 9580932.34B/s]\r 68%|██████▊   | 247257088/363423424 [00:16&lt;00:12, 9268009.24B/s]\r 68%|██████▊   | 248563712/363423424 [00:16&lt;00:11, 9678800.59B/s]\r 69%|██████▊   | 249544704/363423424 [00:16&lt;00:12, 9281071.84B/s]\r 69%|██████▉   | 250873856/363423424 [00:16&lt;00:11, 9796551.85B/s]\r 69%|██████▉   | 251870208/363423424 [00:16&lt;00:11, 9484088.36B/s]\r 70%|██████▉   | 253200384/363423424 [00:16&lt;00:11, 9883317.93B/s]\r 70%|██████▉   | 254202880/363423424 [00:16&lt;00:11, 9572200.66B/s]\r 70%|███████   | 255543296/363423424 [00:17&lt;00:10, 9967435.13B/s]\r 71%|███████   | 256552960/363423424 [00:17&lt;00:11, 9619145.17B/s]\r 71%|███████   | 257902592/363423424 [00:17&lt;00:10, 10044079.18B/s]\r 71%|███████   | 258920448/363423424 [00:17&lt;00:10, 9644612.21B/s] \r 72%|███████▏  | 260278272/363423424 [00:17&lt;00:10, 10108946.79B/s]\r 72%|███████▏  | 261304320/363423424 [00:17&lt;00:10, 9772053.33B/s] \r 72%|███████▏  | 262670336/363423424 [00:17&lt;00:09, 10186863.33B/s]\r 73%|███████▎  | 263702528/363423424 [00:17&lt;00:10, 9810007.04B/s] \r 73%|███████▎  | 265062400/363423424 [00:18&lt;00:09, 10227001.25B/s]\r 73%|███████▎  | 266098688/363423424 [00:18&lt;00:09, 9849151.60B/s] \r 74%|███████▎  | 267470848/363423424 [00:18&lt;00:09, 10281660.46B/s]\r 74%|███████▍  | 268513280/363423424 [00:18&lt;00:09, 9906910.62B/s] \r 74%|███████▍  | 269879296/363423424 [00:18&lt;00:09, 10288152.07B/s]\r 75%|███████▍  | 270920704/363423424 [00:18&lt;00:09, 9944383.33B/s] \r 75%|███████▍  | 272304128/363423424 [00:18&lt;00:08, 10341966.22B/s]\r 75%|███████▌  | 273350656/363423424 [00:18&lt;00:09, 9989430.93B/s] \r 76%|███████▌  | 274728960/363423424 [00:18&lt;00:08, 10374003.05B/s]\r 76%|███████▌  | 275778560/363423424 [00:19&lt;00:08, 10020651.01B/s]\r 76%|███████▋  | 277153792/363423424 [00:19&lt;00:08, 10390918.85B/s]\r 77%|███████▋  | 278204416/363423424 [00:19&lt;00:08, 10037003.55B/s]\r 77%|███████▋  | 279578624/363423424 [00:19&lt;00:08, 10390907.18B/s]\r 77%|███████▋  | 280628224/363423424 [00:19&lt;00:08, 10054808.56B/s]\r 78%|███████▊  | 282003456/363423424 [00:19&lt;00:07, 10399117.19B/s]\r 78%|███████▊  | 283054080/363423424 [00:19&lt;00:07, 10068604.11B/s]\r 78%|███████▊  | 284444672/363423424 [00:19&lt;00:07, 10433822.99B/s]\r 79%|███████▊  | 285498368/363423424 [00:20&lt;00:07, 10103677.79B/s]\r 79%|███████▉  | 286771200/363423424 [00:20&lt;00:07, 10769526.02B/s]\r 79%|███████▉  | 287866880/363423424 [00:20&lt;00:07, 9873174.39B/s] \r 80%|███████▉  | 289118208/363423424 [00:20&lt;00:07, 10539822.01B/s]\r 80%|███████▉  | 290204672/363423424 [00:20&lt;00:07, 9789841.97B/s] \r 80%|████████  | 291239936/363423424 [00:20&lt;00:07, 9951776.24B/s]\r 80%|████████  | 292538368/363423424 [00:20&lt;00:06, 10548440.64B/s]\r 81%|████████  | 293619712/363423424 [00:20&lt;00:06, 10200788.40B/s]\r 81%|████████  | 294979584/363423424 [00:20&lt;00:06, 10516405.91B/s]\r 81%|████████▏ | 296048640/363423424 [00:21&lt;00:06, 10132654.89B/s]\r 82%|████████▏ | 297404416/363423424 [00:21&lt;00:06, 10466992.52B/s]\r 82%|████████▏ | 298465280/363423424 [00:21&lt;00:06, 10096364.38B/s]\r 83%|████████▎ | 299829248/363423424 [00:21&lt;00:06, 10432279.00B/s]\r 83%|████████▎ | 300883968/363423424 [00:21&lt;00:06, 10065044.81B/s]\r 83%|████████▎ | 302139392/363423424 [00:21&lt;00:05, 10700432.06B/s]\r 83%|████████▎ | 303227904/363423424 [00:21&lt;00:06, 9838275.81B/s] \r 84%|████████▍ | 304425984/363423424 [00:21&lt;00:05, 10395955.31B/s]\r 84%|████████▍ | 305498112/363423424 [00:21&lt;00:05, 10466862.84B/s]\r 84%|████████▍ | 306564096/363423424 [00:22&lt;00:05, 10098371.38B/s]\r 85%|████████▍ | 307836928/363423424 [00:22&lt;00:05, 10765161.99B/s]\r 85%|████████▌ | 308937728/363423424 [00:22&lt;00:05, 9905659.18B/s] \r 85%|████████▌ | 310125568/363423424 [00:22&lt;00:05, 10424805.98B/s]\r 86%|████████▌ | 311196672/363423424 [00:22&lt;00:04, 10503907.30B/s]\r 86%|████████▌ | 312267776/363423424 [00:22&lt;00:05, 10150483.61B/s]\r 86%|████████▋ | 313536512/363423424 [00:22&lt;00:04, 10797958.16B/s]\r 87%|████████▋ | 314639360/363423424 [00:22&lt;00:04, 9935966.07B/s] \r 87%|████████▋ | 315869184/363423424 [00:22&lt;00:04, 10543070.97B/s]\r 87%|████████▋ | 316954624/363423424 [00:23&lt;00:04, 10597893.30B/s]\r 88%|████████▊ | 318036992/363423424 [00:23&lt;00:04, 9888156.65B/s] \r 88%|████████▊ | 319342592/363423424 [00:23&lt;00:04, 10501962.83B/s]\r 88%|████████▊ | 320420864/363423424 [00:23&lt;00:04, 10181177.12B/s]\r 88%|████████▊ | 321610752/363423424 [00:23&lt;00:03, 10640951.32B/s]\r 89%|████████▉ | 322717696/363423424 [00:23&lt;00:04, 9934835.95B/s] \r 89%|████████▉ | 323911680/363423424 [00:23&lt;00:03, 10461621.41B/s]\r 89%|████████▉ | 325109760/363423424 [00:23&lt;00:03, 10763394.63B/s]\r 90%|████████▉ | 326205440/363423424 [00:23&lt;00:03, 10416328.94B/s]\r 90%|█████████ | 327452672/363423424 [00:24&lt;00:03, 10921048.47B/s]\r 90%|█████████ | 328562688/363423424 [00:24&lt;00:03, 10124383.74B/s]\r 91%|█████████ | 329754624/363423424 [00:24&lt;00:03, 10603036.71B/s]\r 91%|█████████ | 330942464/363423424 [00:24&lt;00:02, 10866711.65B/s]\r 91%|█████████▏| 332047360/363423424 [00:24&lt;00:02, 10516843.75B/s]\r 92%|█████████▏| 333264896/363423424 [00:24&lt;00:02, 10964908.25B/s]\r 92%|█████████▏| 334376960/363423424 [00:24&lt;00:02, 10987026.00B/s]\r 92%|█████████▏| 335486976/363423424 [00:24&lt;00:02, 10616927.18B/s]\r 93%|█████████▎| 336713728/363423424 [00:24&lt;00:02, 11062965.52B/s]\r 93%|█████████▎| 337832960/363423424 [00:25&lt;00:02, 10243624.17B/s]\r 93%|█████████▎| 339046400/363423424 [00:25&lt;00:02, 10745615.19B/s]\r 94%|█████████▎| 340281344/363423424 [00:25&lt;00:02, 11064563.44B/s]\r 94%|█████████▍| 341405696/363423424 [00:25&lt;00:02, 10750409.73B/s]\r 94%|█████████▍| 342657024/363423424 [00:25&lt;00:01, 11224220.31B/s]\r 95%|█████████▍| 343794688/363423424 [00:25&lt;00:01, 11239417.33B/s]\r 95%|█████████▍| 344929280/363423424 [00:25&lt;00:01, 10900233.29B/s]\r 95%|█████████▌| 346231808/363423424 [00:25&lt;00:01, 11460814.71B/s]\r 96%|█████████▌| 347393024/363423424 [00:25&lt;00:01, 10570336.11B/s]\r 96%|█████████▌| 348678144/363423424 [00:25&lt;00:01, 11164625.88B/s]\r 96%|█████████▋| 349980672/363423424 [00:26&lt;00:01, 11536720.38B/s]\r 97%|█████████▋| 351156224/363423424 [00:26&lt;00:01, 11183235.95B/s]\r 97%|█████████▋| 352497664/363423424 [00:26&lt;00:00, 11769936.27B/s]\r 97%|█████████▋| 353695744/363423424 [00:26&lt;00:00, 11793900.21B/s]\r 98%|█████████▊| 354889728/363423424 [00:26&lt;00:00, 11440254.24B/s]\r 98%|█████████▊| 356111360/363423424 [00:26&lt;00:00, 11662116.65B/s]\r 98%|█████████▊| 357367808/363423424 [00:26&lt;00:00, 11918774.28B/s]\r 99%|█████████▊| 358567936/363423424 [00:26&lt;00:00, 11549269.68B/s]\r 99%|█████████▉| 359937024/363423424 [00:26&lt;00:00, 12117373.44B/s]\r 99%|█████████▉| 361162752/363423424 [00:27&lt;00:00, 12144011.14B/s]\r100%|█████████▉| 362386432/363423424 [00:27&lt;00:00, 11808169.67B/s]\r100%|██████████| 363423424/363423424 [00:27&lt;00:00, 13345841.22B/s]\n</div>"]}}],"execution_count":64},{"cell_type":"code","source":["%fs\nmkdirs dbfs:/ml/judith/transformers/mrpc/2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res21: Boolean = true\n</div>"]}}],"execution_count":65},{"cell_type":"code","source":["%sh\nmkdir /tmp/mrpc/2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":66},{"cell_type":"code","source":["# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n\n# Train and evaluate using tf.keras.Model.fit()\nhistory = model.fit(train_dataset, epochs=2, steps_per_epoch=115,\n                    validation_data=valid_dataset, validation_steps=7)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-145002&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span> <span class=\"ansi-red-fg\"># Save model</span>\n<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\"> </span>model<span class=\"ansi-blue-fg\">.</span>save_pretrained<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/tmp/mrpc/2/&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span> tokenizer<span class=\"ansi-blue-fg\">.</span>save_pretrained<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/tmp/mrpc/2/&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/transformers/modeling_tf_utils.py</span> in <span class=\"ansi-cyan-fg\">save_pretrained</span><span class=\"ansi-blue-fg\">(self, save_directory)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>             can be re<span class=\"ansi-blue-fg\">-</span>loaded using the<span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">`</span><span class=\"ansi-blue-fg\">:</span>func<span class=\"ansi-blue-fg\">:</span><span class=\"ansi-red-fg\">`</span><span class=\"ansi-blue-fg\">~</span>transformers<span class=\"ansi-blue-fg\">.</span>PreTrainedModel<span class=\"ansi-blue-fg\">.</span>from_pretrained<span class=\"ansi-red-fg\">`</span><span class=\"ansi-red-fg\">`</span> <span class=\"ansi-green-fg\">class</span> method<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 130</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">assert</span> os<span class=\"ansi-blue-fg\">.</span>path<span class=\"ansi-blue-fg\">.</span>isdir<span class=\"ansi-blue-fg\">(</span>save_directory<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;Saving path should be a directory where the model and configuration can be saved&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>         <span class=\"ansi-red-fg\"># Save configuration file</span>\n\n<span class=\"ansi-red-fg\">AssertionError</span>: Saving path should be a directory where the model and configuration can be saved</div>"]}}],"execution_count":67},{"cell_type":"code","source":["# Save model\nmodel.save_pretrained(\"/tmp/mrpc/2/\")\ntokenizer.save_pretrained(\"/tmp/mrpc/2/\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: (&#39;/tmp/mrpc/2/vocab.txt&#39;,\n &#39;/tmp/mrpc/2/special_tokens_map.json&#39;,\n &#39;/tmp/mrpc/2/added_tokens.json&#39;)</div>"]}}],"execution_count":68},{"cell_type":"code","source":["%fs\nls dbfs:/ml/judith/transformers/mrpc/1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/ml/judith/transformers/mrpc/1/added_tokens.json</td><td>added_tokens.json</td><td>2</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/1/config.json</td><td>config.json</td><td>543</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/1/special_tokens_map.json</td><td>special_tokens_map.json</td><td>112</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/1/tf_model.h5</td><td>tf_model.h5</td><td>433518744</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/1/tokenizer_config.json</td><td>tokenizer_config.json</td><td>59</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/1/vocab.txt</td><td>vocab.txt</td><td>213450</td></tr></tbody></table></div>"]}}],"execution_count":69},{"cell_type":"code","source":["%fs\ncp -r file:/tmp/mrpc/2 dbfs:/ml/judith/transformers/mrpc/2"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: Boolean = true\n</div>"]}}],"execution_count":70},{"cell_type":"code","source":["# Load dataset, tokenizer, model from pretrained model/vocabulary\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-cased')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/213450 [00:00&lt;?, ?B/s]\r 24%|██▍       | 52224/213450 [00:00&lt;00:00, 369507.54B/s]\r100%|██████████| 213450/213450 [00:00&lt;00:00, 990101.12B/s]\n\r  0%|          | 0/313 [00:00&lt;?, ?B/s]\r100%|██████████| 313/313 [00:00&lt;00:00, 241459.84B/s]\n\r  0%|          | 0/526681800 [00:00&lt;?, ?B/s]\r  0%|          | 52224/526681800 [00:00&lt;25:01, 350745.44B/s]\r  0%|          | 295936/526681800 [00:00&lt;19:07, 458578.02B/s]\r  0%|          | 1253376/526681800 [00:00&lt;13:46, 635483.17B/s]\r  1%|          | 3804160/526681800 [00:00&lt;09:42, 898242.44B/s]\r  1%|          | 5213184/526681800 [00:00&lt;07:00, 1240794.28B/s]\r  2%|▏         | 7982080/526681800 [00:00&lt;05:01, 1722927.78B/s]\r  2%|▏         | 10927104/526681800 [00:00&lt;03:34, 2401116.75B/s]\r  2%|▏         | 12733440/526681800 [00:01&lt;02:40, 3201977.64B/s]\r  3%|▎         | 15616000/526681800 [00:01&lt;01:57, 4366352.51B/s]\r  3%|▎         | 17643520/526681800 [00:01&lt;01:31, 5575892.69B/s]\r  4%|▍         | 20433920/526681800 [00:01&lt;01:09, 7336454.69B/s]\r  4%|▍         | 22594560/526681800 [00:01&lt;00:57, 8817294.44B/s]\r  5%|▍         | 25267200/526681800 [00:01&lt;00:46, 10832505.75B/s]\r  5%|▌         | 27372544/526681800 [00:01&lt;00:40, 12448727.89B/s]\r  6%|▌         | 30018560/526681800 [00:01&lt;00:34, 14443380.82B/s]\r  6%|▌         | 32143360/526681800 [00:01&lt;00:32, 15009489.62B/s]\r  7%|▋         | 34786304/526681800 [00:02&lt;00:28, 17244007.36B/s]\r  7%|▋         | 36967424/526681800 [00:02&lt;00:28, 17237080.88B/s]\r  8%|▊         | 39619584/526681800 [00:02&lt;00:25, 19259669.09B/s]\r  8%|▊         | 41845760/526681800 [00:02&lt;00:25, 18839163.54B/s]\r  8%|▊         | 44312576/526681800 [00:02&lt;00:23, 20276288.25B/s]\r  9%|▉         | 46520320/526681800 [00:02&lt;00:24, 19462739.76B/s]\r  9%|▉         | 48942080/526681800 [00:02&lt;00:23, 20676514.25B/s]\r 10%|▉         | 51124224/526681800 [00:02&lt;00:24, 19592741.02B/s]\r 10%|█         | 53695488/526681800 [00:02&lt;00:22, 21098403.78B/s]\r 11%|█         | 55902208/526681800 [00:03&lt;00:23, 19924126.48B/s]\r 11%|█         | 58464256/526681800 [00:03&lt;00:21, 21347033.26B/s]\r 12%|█▏        | 60684288/526681800 [00:03&lt;00:23, 20080018.33B/s]\r 12%|█▏        | 63251456/526681800 [00:03&lt;00:21, 21483357.80B/s]\r 12%|█▏        | 65480704/526681800 [00:03&lt;00:22, 20155345.98B/s]\r 13%|█▎        | 67988480/526681800 [00:03&lt;00:21, 21415444.11B/s]\r 13%|█▎        | 70203392/526681800 [00:03&lt;00:22, 20166458.31B/s]\r 14%|█▍        | 72742912/526681800 [00:03&lt;00:21, 21492729.90B/s]\r 14%|█▍        | 74962944/526681800 [00:04&lt;00:22, 20277826.94B/s]\r 15%|█▍        | 77499392/526681800 [00:04&lt;00:20, 21573625.55B/s]\r 15%|█▌        | 79724544/526681800 [00:04&lt;00:22, 20298732.40B/s]\r 16%|█▌        | 82247680/526681800 [00:04&lt;00:20, 21562903.69B/s]\r 16%|█▌        | 84469760/526681800 [00:04&lt;00:21, 20211684.44B/s]\r 16%|█▋        | 86810624/526681800 [00:04&lt;00:20, 21074763.48B/s]\r 17%|█▋        | 88972288/526681800 [00:04&lt;00:21, 20055464.12B/s]\r 17%|█▋        | 91286528/526681800 [00:04&lt;00:20, 20890733.78B/s]\r 18%|█▊        | 93572096/526681800 [00:04&lt;00:20, 20802772.37B/s]\r 18%|█▊        | 95682560/526681800 [00:04&lt;00:20, 20556419.90B/s]\r 19%|█▊        | 98104320/526681800 [00:05&lt;00:19, 21532736.55B/s]\r 19%|█▉        | 100285440/526681800 [00:05&lt;00:21, 20023470.46B/s]\r 20%|█▉        | 102861824/526681800 [00:05&lt;00:19, 21451726.57B/s]\r 20%|█▉        | 105064448/526681800 [00:05&lt;00:20, 20087779.61B/s]\r 20%|██        | 107637760/526681800 [00:05&lt;00:19, 21501197.67B/s]\r 21%|██        | 109856768/526681800 [00:05&lt;00:20, 20129745.61B/s]\r 21%|██▏       | 112487424/526681800 [00:05&lt;00:19, 21654905.10B/s]\r 22%|██▏       | 114732032/526681800 [00:05&lt;00:20, 20279350.35B/s]\r 22%|██▏       | 117149696/526681800 [00:05&lt;00:19, 21309409.52B/s]\r 23%|██▎       | 119346176/526681800 [00:06&lt;00:20, 20176793.41B/s]\r 23%|██▎       | 121780224/526681800 [00:06&lt;00:19, 21268176.77B/s]\r 24%|██▎       | 123963392/526681800 [00:06&lt;00:20, 20104214.42B/s]\r 24%|██▍       | 126369792/526681800 [00:06&lt;00:18, 21147630.57B/s]\r 24%|██▍       | 128536576/526681800 [00:06&lt;00:19, 20392018.28B/s]\r 25%|██▍       | 130780160/526681800 [00:06&lt;00:18, 20847580.98B/s]\r 25%|██▌       | 133204992/526681800 [00:06&lt;00:18, 21391543.60B/s]\r 26%|██▌       | 135370752/526681800 [00:06&lt;00:18, 21047086.38B/s]\r 26%|██▌       | 137760768/526681800 [00:06&lt;00:17, 21828635.20B/s]\r 27%|██▋       | 139965440/526681800 [00:07&lt;00:18, 20556287.33B/s]\r 27%|██▋       | 142462976/526681800 [00:07&lt;00:17, 21708489.88B/s]\r 27%|██▋       | 144672768/526681800 [00:07&lt;00:18, 20355616.49B/s]\r 28%|██▊       | 147081216/526681800 [00:07&lt;00:17, 21346705.53B/s]\r 28%|██▊       | 149260288/526681800 [00:07&lt;00:18, 20356776.51B/s]\r 29%|██▉       | 151521280/526681800 [00:07&lt;00:17, 20980485.24B/s]\r 29%|██▉       | 153799680/526681800 [00:07&lt;00:17, 21262649.70B/s]\r 30%|██▉       | 155950080/526681800 [00:07&lt;00:17, 20982793.96B/s]\r 30%|███       | 158338048/526681800 [00:07&lt;00:16, 21774355.54B/s]\r 30%|███       | 160535552/526681800 [00:08&lt;00:17, 20503793.12B/s]\r 31%|███       | 162941952/526681800 [00:08&lt;00:16, 21454031.60B/s]\r 31%|███▏      | 165120000/526681800 [00:08&lt;00:17, 20362950.92B/s]\r 32%|███▏      | 167442432/526681800 [00:08&lt;00:16, 21143873.37B/s]\r 32%|███▏      | 169659392/526681800 [00:08&lt;00:16, 21249236.50B/s]\r 33%|███▎      | 171806720/526681800 [00:08&lt;00:16, 20908152.99B/s]\r 33%|███▎      | 174247936/526681800 [00:08&lt;00:16, 21848247.50B/s]\r 34%|███▎      | 176455680/526681800 [00:08&lt;00:16, 20604280.94B/s]\r 34%|███▍      | 178890752/526681800 [00:08&lt;00:16, 21600521.51B/s]\r 34%|███▍      | 181085184/526681800 [00:09&lt;00:16, 20329582.75B/s]\r 35%|███▍      | 183445504/526681800 [00:09&lt;00:16, 21210905.95B/s]\r 35%|███▌      | 185604096/526681800 [00:09&lt;00:16, 20267446.47B/s]\r 36%|███▌      | 187898880/526681800 [00:09&lt;00:16, 21002830.75B/s]\r 36%|███▌      | 190254080/526681800 [00:09&lt;00:15, 21328041.79B/s]\r 37%|███▋      | 192410624/526681800 [00:09&lt;00:16, 20595897.38B/s]\r 37%|███▋      | 195005440/526681800 [00:09&lt;00:15, 21308987.93B/s]\r 37%|███▋      | 197157888/526681800 [00:09&lt;00:15, 21038321.78B/s]\r 38%|███▊      | 199538688/526681800 [00:09&lt;00:15, 21795865.99B/s]\r 38%|███▊      | 201737216/526681800 [00:10&lt;00:15, 20484911.39B/s]\r 39%|███▉      | 204181504/526681800 [00:10&lt;00:14, 21530737.30B/s]\r 39%|███▉      | 206369792/526681800 [00:10&lt;00:15, 20427488.87B/s]\r 40%|███▉      | 208718848/526681800 [00:10&lt;00:14, 21258697.94B/s]\r 40%|████      | 210879488/526681800 [00:10&lt;00:14, 21124921.15B/s]\r 40%|████      | 213016576/526681800 [00:10&lt;00:14, 20963466.56B/s]\r 41%|████      | 215345152/526681800 [00:10&lt;00:14, 21607442.03B/s]\r 41%|████▏     | 217523200/526681800 [00:10&lt;00:15, 20483421.78B/s]\r 42%|████▏     | 219843584/526681800 [00:10&lt;00:14, 21228063.49B/s]\r 42%|████▏     | 221990912/526681800 [00:10&lt;00:14, 21164304.43B/s]\r 43%|████▎     | 224124928/526681800 [00:11&lt;00:14, 20922629.07B/s]\r 43%|████▎     | 226331648/526681800 [00:11&lt;00:14, 21249477.78B/s]\r 43%|████▎     | 228466688/526681800 [00:11&lt;00:14, 20493619.23B/s]\r 44%|████▍     | 230722560/526681800 [00:11&lt;00:14, 21072066.82B/s]\r 44%|████▍     | 233049088/526681800 [00:11&lt;00:13, 21262406.44B/s]\r 45%|████▍     | 235185152/526681800 [00:11&lt;00:13, 21112725.15B/s]\r 45%|████▌     | 237340672/526681800 [00:11&lt;00:13, 21241892.28B/s]\r 45%|████▌     | 239470592/526681800 [00:11&lt;00:14, 20426646.27B/s]\r 46%|████▌     | 241756160/526681800 [00:11&lt;00:13, 21097679.39B/s]\r 46%|████▋     | 244157440/526681800 [00:12&lt;00:13, 21370194.35B/s]\r 47%|████▋     | 246304768/526681800 [00:12&lt;00:13, 21221891.40B/s]\r 47%|████▋     | 248457216/526681800 [00:12&lt;00:13, 21309769.80B/s]\r 48%|████▊     | 250593280/526681800 [00:12&lt;00:13, 20461484.95B/s]\r 48%|████▊     | 252868608/526681800 [00:12&lt;00:12, 21097601.33B/s]\r 48%|████▊     | 255249408/526681800 [00:12&lt;00:12, 21339881.47B/s]\r 49%|████▉     | 257393664/526681800 [00:12&lt;00:12, 21205066.02B/s]\r 49%|████▉     | 259553280/526681800 [00:12&lt;00:12, 21319053.12B/s]\r 50%|████▉     | 261690368/526681800 [00:12&lt;00:12, 20455290.30B/s]\r 50%|█████     | 264024064/526681800 [00:12&lt;00:12, 21242169.91B/s]\r 51%|█████     | 266341376/526681800 [00:13&lt;00:12, 21291327.18B/s]\r 51%|█████     | 268481536/526681800 [00:13&lt;00:12, 21159039.81B/s]\r 51%|█████▏    | 270653440/526681800 [00:13&lt;00:12, 21322986.78B/s]\r 52%|█████▏    | 272791552/526681800 [00:13&lt;00:12, 20467347.47B/s]\r 52%|█████▏    | 275090432/526681800 [00:13&lt;00:11, 21051524.12B/s]\r 53%|█████▎    | 277433344/526681800 [00:13&lt;00:11, 21268356.76B/s]\r 53%|█████▎    | 279569408/526681800 [00:13&lt;00:11, 21077604.78B/s]\r 53%|█████▎    | 281754624/526681800 [00:13&lt;00:11, 21303615.12B/s]\r 54%|█████▍    | 283890688/526681800 [00:13&lt;00:11, 20422161.06B/s]\r 54%|█████▍    | 286198784/526681800 [00:14&lt;00:11, 21130925.79B/s]\r 55%|█████▍    | 288525312/526681800 [00:14&lt;00:11, 21172484.39B/s]\r 55%|█████▌    | 290653184/526681800 [00:14&lt;00:11, 21065828.85B/s]\r 56%|█████▌    | 292916224/526681800 [00:14&lt;00:10, 21509772.10B/s]\r 56%|█████▌    | 295074816/526681800 [00:14&lt;00:11, 20642371.47B/s]\r 56%|█████▋    | 297316352/526681800 [00:14&lt;00:10, 21142938.19B/s]\r 57%|█████▋    | 299633664/526681800 [00:14&lt;00:10, 21190687.11B/s]\r 57%|█████▋    | 301761536/526681800 [00:14&lt;00:10, 21129924.84B/s]\r 58%|█████▊    | 303991808/526681800 [00:14&lt;00:10, 21465610.47B/s]\r 58%|█████▊    | 306144256/526681800 [00:14&lt;00:10, 20596798.36B/s]\r 59%|█████▊    | 308415488/526681800 [00:15&lt;00:10, 21170681.34B/s]\r 59%|█████▉    | 310725632/526681800 [00:15&lt;00:10, 21175279.81B/s]\r 59%|█████▉    | 312852480/526681800 [00:15&lt;00:10, 21074555.53B/s]\r 60%|█████▉    | 315132928/526681800 [00:15&lt;00:09, 21561298.84B/s]\r 60%|██████    | 317296640/526681800 [00:15&lt;00:10, 20653771.34B/s]\r 61%|██████    | 319561728/526681800 [00:15&lt;00:09, 21213747.92B/s]\r 61%|██████    | 321817600/526681800 [00:15&lt;00:09, 21106701.10B/s]\r 62%|██████▏   | 323938304/526681800 [00:15&lt;00:09, 21059946.00B/s]\r 62%|██████▏   | 326227968/526681800 [00:15&lt;00:09, 21577875.19B/s]\r 62%|██████▏   | 328393728/526681800 [00:16&lt;00:09, 20626264.98B/s]\r 63%|██████▎   | 330632192/526681800 [00:16&lt;00:09, 21086814.55B/s]\r 63%|██████▎   | 332753920/526681800 [00:16&lt;00:09, 21087210.92B/s]\r 64%|██████▎   | 334871552/526681800 [00:16&lt;00:09, 20533679.89B/s]\r 64%|██████▍   | 337349632/526681800 [00:16&lt;00:08, 21618243.97B/s]\r 64%|██████▍   | 339533824/526681800 [00:16&lt;00:09, 20551273.77B/s]\r 65%|██████▍   | 341896192/526681800 [00:16&lt;00:08, 21384518.18B/s]\r 65%|██████▌   | 344061952/526681800 [00:16&lt;00:08, 20962654.44B/s]\r 66%|██████▌   | 346179584/526681800 [00:16&lt;00:08, 20759135.04B/s]\r 66%|██████▌   | 348490752/526681800 [00:16&lt;00:08, 21085751.07B/s]\r 67%|██████▋   | 350611456/526681800 [00:17&lt;00:08, 20703410.71B/s]\r 67%|██████▋   | 352979968/526681800 [00:17&lt;00:08, 21515463.11B/s]\r 67%|██████▋   | 355146752/526681800 [00:17&lt;00:08, 21054711.21B/s]\r 68%|██████▊   | 357265408/526681800 [00:17&lt;00:08, 20791268.53B/s]\r 68%|██████▊   | 359582720/526681800 [00:17&lt;00:07, 20994092.38B/s]\r 69%|██████▊   | 361690112/526681800 [00:17&lt;00:07, 20676787.58B/s]\r 69%|██████▉   | 364121088/526681800 [00:17&lt;00:07, 21639682.33B/s]\r 70%|██████▉   | 366301184/526681800 [00:17&lt;00:07, 20304173.05B/s]\r 70%|███████   | 368724992/526681800 [00:17&lt;00:07, 21340234.16B/s]\r 70%|███████   | 370892800/526681800 [00:18&lt;00:07, 21357596.69B/s]\r 71%|███████   | 373052416/526681800 [00:18&lt;00:07, 20719508.14B/s]\r 71%|███████▏  | 375442432/526681800 [00:18&lt;00:07, 21026592.82B/s]\r 72%|███████▏  | 377561088/526681800 [00:18&lt;00:07, 20621354.84B/s]\r 72%|███████▏  | 380024832/526681800 [00:18&lt;00:06, 21680958.07B/s]\r 73%|███████▎  | 382217216/526681800 [00:18&lt;00:07, 20443187.77B/s]\r 73%|███████▎  | 384650240/526681800 [00:18&lt;00:06, 21469988.35B/s]\r 73%|███████▎  | 386833408/526681800 [00:18&lt;00:06, 20675353.92B/s]\r 74%|███████▍  | 389011456/526681800 [00:18&lt;00:06, 20993449.29B/s]\r 74%|███████▍  | 391285760/526681800 [00:18&lt;00:06, 21091800.28B/s]\r 75%|███████▍  | 393411584/526681800 [00:19&lt;00:06, 20807000.52B/s]\r 75%|███████▌  | 395786240/526681800 [00:19&lt;00:06, 21608568.59B/s]\r 76%|███████▌  | 397964288/526681800 [00:19&lt;00:06, 20372113.91B/s]\r 76%|███████▌  | 400427008/526681800 [00:19&lt;00:05, 21485747.25B/s]\r 76%|███████▋  | 402610176/526681800 [00:19&lt;00:05, 21384148.06B/s]\r 77%|███████▋  | 404773888/526681800 [00:19&lt;00:05, 20751004.12B/s]\r 77%|███████▋  | 407145472/526681800 [00:19&lt;00:05, 21004091.15B/s]\r 78%|███████▊  | 409262080/526681800 [00:19&lt;00:05, 20782999.52B/s]\r 78%|███████▊  | 411555840/526681800 [00:19&lt;00:05, 21384467.78B/s]\r 79%|███████▊  | 413707264/526681800 [00:20&lt;00:05, 21399418.69B/s]\r 79%|███████▉  | 415856640/526681800 [00:20&lt;00:05, 20804361.74B/s]\r 79%|███████▉  | 418237440/526681800 [00:20&lt;00:05, 21017483.15B/s]\r 80%|███████▉  | 420346880/526681800 [00:20&lt;00:05, 20809573.56B/s]\r 80%|████████  | 422644736/526681800 [00:20&lt;00:04, 21325783.78B/s]\r 81%|████████  | 424832000/526681800 [00:20&lt;00:04, 21486395.18B/s]\r 81%|████████  | 426986496/526681800 [00:20&lt;00:04, 20771190.67B/s]\r 82%|████████▏ | 429329408/526681800 [00:20&lt;00:04, 20922004.74B/s]\r 82%|████████▏ | 431428608/526681800 [00:20&lt;00:04, 20820197.04B/s]\r 82%|████████▏ | 433736704/526681800 [00:21&lt;00:04, 21341075.97B/s]\r 83%|████████▎ | 435877888/526681800 [00:21&lt;00:04, 21334052.10B/s]\r 83%|████████▎ | 438016000/526681800 [00:21&lt;00:04, 20767010.96B/s]\r 84%|████████▎ | 440421376/526681800 [00:21&lt;00:04, 20990028.16B/s]\r 84%|████████▍ | 442525696/526681800 [00:21&lt;00:04, 20560953.17B/s]\r 84%|████████▍ | 444910592/526681800 [00:21&lt;00:03, 21444389.07B/s]\r 85%|████████▍ | 447069184/526681800 [00:21&lt;00:03, 20323022.41B/s]\r 85%|████████▌ | 449358848/526681800 [00:21&lt;00:03, 21031125.52B/s]\r 86%|████████▌ | 451513344/526681800 [00:21&lt;00:03, 21008389.59B/s]\r 86%|████████▌ | 453629952/526681800 [00:21&lt;00:03, 20904101.35B/s]\r 87%|████████▋ | 455983104/526681800 [00:22&lt;00:03, 21628363.31B/s]\r 87%|████████▋ | 458160128/526681800 [00:22&lt;00:03, 20440416.26B/s]\r 87%|████████▋ | 460488704/526681800 [00:22&lt;00:03, 21217749.90B/s]\r 88%|████████▊ | 462635008/526681800 [00:22&lt;00:03, 21079051.66B/s]\r 88%|████████▊ | 464759808/526681800 [00:22&lt;00:02, 21012986.70B/s]\r 89%|████████▊ | 467078144/526681800 [00:22&lt;00:02, 21617059.14B/s]\r 89%|████████▉ | 469253120/526681800 [00:22&lt;00:02, 20442027.43B/s]\r 90%|████████▉ | 471546880/526681800 [00:22&lt;00:02, 21130983.22B/s]\r 90%|████████▉ | 473713664/526681800 [00:22&lt;00:02, 21041796.31B/s]\r 90%|█████████ | 475833344/526681800 [00:23&lt;00:02, 21069189.24B/s]\r 91%|█████████ | 478106624/526681800 [00:23&lt;00:02, 21541480.97B/s]\r 91%|█████████ | 480271360/526681800 [00:23&lt;00:02, 21272099.17B/s]\r 92%|█████████▏| 482406400/526681800 [00:23&lt;00:02, 20644520.69B/s]\r 92%|█████████▏| 484805632/526681800 [00:23&lt;00:01, 21016862.81B/s]\r 92%|█████████▏| 486916096/526681800 [00:23&lt;00:01, 20998109.63B/s]\r 93%|█████████▎| 489276416/526681800 [00:23&lt;00:01, 21716994.53B/s]\r 93%|█████████▎| 491458560/526681800 [00:23&lt;00:01, 20453956.45B/s]\r 94%|█████████▍| 493780992/526681800 [00:23&lt;00:01, 21212404.00B/s]\r 94%|█████████▍| 495925248/526681800 [00:23&lt;00:01, 21038903.49B/s]\r 95%|█████████▍| 498045952/526681800 [00:24&lt;00:01, 21044852.25B/s]\r 95%|█████████▌| 500415488/526681800 [00:24&lt;00:01, 21775387.35B/s]\r 95%|█████████▌| 502607872/526681800 [00:24&lt;00:01, 20513985.15B/s]\r 96%|█████████▌| 504908800/526681800 [00:24&lt;00:01, 21199983.77B/s]\r 96%|█████████▋| 507053056/526681800 [00:24&lt;00:00, 20983613.05B/s]\r 97%|█████████▋| 509168640/526681800 [00:24&lt;00:00, 20923184.09B/s]\r 97%|█████████▋| 511549440/526681800 [00:24&lt;00:00, 21711864.47B/s]\r 98%|█████████▊| 513736704/526681800 [00:24&lt;00:00, 20551878.82B/s]\r 98%|█████████▊| 516072448/526681800 [00:24&lt;00:00, 21320098.16B/s]\r 98%|█████████▊| 518228992/526681800 [00:25&lt;00:00, 21099168.69B/s]\r 99%|█████████▉| 520358912/526681800 [00:25&lt;00:00, 21135556.14B/s]\r 99%|█████████▉| 522638336/526681800 [00:25&lt;00:00, 21606903.19B/s]\r100%|█████████▉| 524810240/526681800 [00:25&lt;00:00, 20440617.85B/s]\r100%|██████████| 526681800/526681800 [00:25&lt;00:00, 20729603.82B/s]\n</div>"]}}],"execution_count":71},{"cell_type":"code","source":["data = tensorflow_datasets.load('glue/mrpc')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">INFO:absl:Load pre-computed datasetinfo (eg: splits) from bucket.\nINFO:absl:Loading info from GCS for glue/mrpc/0.0.2\nINFO:absl:Generating dataset glue (/root/tensorflow_datasets/glue/mrpc/0.0.2)\n<span class=\"ansi-bold\">Downloading and preparing dataset glue (1.43 MiB) to /root/tensorflow_datasets/glue/mrpc/0.0.2...</span>\n\rDl Completed...: 0 url [00:00, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&amp;token=ec5c0836-31d5-48f4-b431-7480817f1adc into /root/tensorflow_datasets/downloads/fire.goog.com_v0_b_mtl-sent-repr.apps.com_o_2FjSIMlCiqs1QSmIykr4IRPnEHjPuGwAz5i40v8K9U0Z8.tsvalt=media&amp;token=ec5c0836-31d5-48f4-b431-7480817f1adc.tmp.a2894c73354f4e7e868edd44e0e01ec9...\n\rDl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt into /root/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_trainfGxPZuQWGBti4Tbd1YNOwQr-OqxPejJ7gcp0Al6mlSk.txt.tmp.5df8a9158db84131a1ca68864942ff5c...\n\rDl Completed...:   0%|          | 0/2 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]INFO:absl:Downloading https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt into /root/tensorflow_datasets/downloads/dl.fbaip.com_sente_sente_msr_parap_test0PdekMcyqYR-w4Rx_d7OTryq0J3RlYRn4rAMajy9Mak.txt.tmp.5a7b6a7559dd4b338ff17ee0b0244026...\n\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n/databricks/python/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  InsecureRequestWarning)\n\rDl Completed...:   0%|          | 0/3 [00:00&lt;?, ? url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  3.45 url/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  3.45 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  3.45 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  33%|███▎      | 1/3 [00:00&lt;00:00,  3.45 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...:  67%|██████▋   | 2/3 [00:00&lt;00:00,  3.85 url/s]\rDl Completed...:  67%|██████▋   | 2/3 [00:00&lt;00:00,  3.85 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\rDl Completed...: 100%|██████████| 3/3 [00:00&lt;00:00,  3.85 url/s]\n\rDl Size...: 0 MiB [00:00, ? MiB/s]\n\n\rDl Completed...: 100%|██████████| 3/3 [00:00&lt;00:00,  5.75 url/s]\nINFO:absl:Generating split train\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r249 examples [00:00, 2488.31 examples/s]\r508 examples [00:00, 2515.48 examples/s]\r758 examples [00:00, 2509.05 examples/s]\r1016 examples [00:00, 2528.87 examples/s]\r1252 examples [00:00, 2472.75 examples/s]\r1505 examples [00:00, 2487.97 examples/s]\r1771 examples [00:00, 2535.99 examples/s]\r2021 examples [00:00, 2522.47 examples/s]\r2278 examples [00:00, 2533.58 examples/s]\r2536 examples [00:01, 2545.02 examples/s]\r2790 examples [00:01, 2543.13 examples/s]\r3040 examples [00:01, 2529.81 examples/s]\r3303 examples [00:01, 2556.36 examples/s]\r3572 examples [00:01, 2594.86 examples/s]\r                                         \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\n\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/3668 [00:00&lt;?, ? examples/s]\n\r                                                           \r                                                       \rINFO:absl:Generating split validation\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r150 examples [00:00, 1489.49 examples/s]\r305 examples [00:00, 1490.30 examples/s]\r                                        \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/408 [00:00&lt;?, ? examples/s]\n\r                                                          \r                                                       \rINFO:absl:Generating split test\nINFO:absl:Writing TFRecords\n\r0 examples [00:00, ? examples/s]\r283 examples [00:00, 2823.27 examples/s]\r550 examples [00:00, 2772.69 examples/s]\r822 examples [00:00, 2753.76 examples/s]\r1097 examples [00:00, 2750.92 examples/s]\r1363 examples [00:00, 2722.62 examples/s]\r1633 examples [00:00, 2713.54 examples/s]\r                                         \r\rShuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]\n\rReading...: 0 examples [00:00, ? examples/s]\n\r                                            \n\rWriting...:   0%|          | 0/1725 [00:00&lt;?, ? examples/s]\n\r                                                           \r                                                       \rINFO:absl:Skipping computing stats for mode ComputeStatsMode.AUTO.\n<span class=\"ansi-bold\">Dataset glue downloaded and prepared to /root/tensorflow_datasets/glue/mrpc/0.0.2. Subsequent calls will reuse this data.</span>\nINFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/0.0.2\n</div>"]}}],"execution_count":72},{"cell_type":"code","source":["# Prepare dataset for GLUE as a tf.data.Dataset instance\ntrain_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\nvalid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\ntrain_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\nvalid_dataset = valid_dataset.batch(64)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":73},{"cell_type":"code","source":["# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \noptimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":74},{"cell_type":"code","source":["# Train and evaluate using tf.keras.Model.fit()\nhistory = model.fit(train_dataset, epochs=2, steps_per_epoch=115,\n                    validation_data=valid_dataset, validation_steps=7)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Train for 115 steps, validate for 7 steps\nEpoch 1/2\n\r  1/115 [..............................] - ETA: 49:53 - loss: 0.7010 - accuracy: 0.4688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2/115 [..............................] - ETA: 26:07 - loss: 0.7182 - accuracy: 0.4531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  3/115 [..............................] - ETA: 18:09 - loss: 0.7013 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/115 [&gt;.............................] - ETA: 14:09 - loss: 0.7084 - accuracy: 0.4922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5/115 [&gt;.............................] - ETA: 11:45 - loss: 0.7028 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  6/115 [&gt;.............................] - ETA: 10:08 - loss: 0.6947 - accuracy: 0.5260\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/115 [&gt;.............................] - ETA: 8:59 - loss: 0.6879 - accuracy: 0.5446 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  8/115 [=&gt;............................] - ETA: 8:06 - loss: 0.6856 - accuracy: 0.5586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  9/115 [=&gt;............................] - ETA: 7:25 - loss: 0.6878 - accuracy: 0.5590\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 10/115 [=&gt;............................] - ETA: 6:52 - loss: 0.6745 - accuracy: 0.5813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 11/115 [=&gt;............................] - ETA: 6:24 - loss: 0.6715 - accuracy: 0.5881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 12/115 [==&gt;...........................] - ETA: 6:02 - loss: 0.6774 - accuracy: 0.5833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13/115 [==&gt;...........................] - ETA: 5:42 - loss: 0.6725 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 14/115 [==&gt;...........................] - ETA: 5:25 - loss: 0.6720 - accuracy: 0.5960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 15/115 [==&gt;...........................] - ETA: 5:10 - loss: 0.6681 - accuracy: 0.6000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 16/115 [===&gt;..........................] - ETA: 4:57 - loss: 0.6619 - accuracy: 0.6113\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 17/115 [===&gt;..........................] - ETA: 4:46 - loss: 0.6644 - accuracy: 0.6085\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 18/115 [===&gt;..........................] - ETA: 4:35 - loss: 0.6636 - accuracy: 0.6094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 19/115 [===&gt;..........................] - ETA: 4:25 - loss: 0.6615 - accuracy: 0.6151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 20/115 [====&gt;.........................] - ETA: 4:16 - loss: 0.6574 - accuracy: 0.6203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 21/115 [====&gt;.........................] - ETA: 4:08 - loss: 0.6530 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 22/115 [====&gt;.........................] - ETA: 4:01 - loss: 0.6473 - accuracy: 0.6307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 23/115 [=====&gt;........................] - ETA: 3:53 - loss: 0.6427 - accuracy: 0.6345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 24/115 [=====&gt;........................] - ETA: 3:47 - loss: 0.6400 - accuracy: 0.6380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 25/115 [=====&gt;........................] - ETA: 3:41 - loss: 0.6328 - accuracy: 0.6450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26/115 [=====&gt;........................] - ETA: 3:35 - loss: 0.6315 - accuracy: 0.6466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 27/115 [======&gt;.......................] - ETA: 3:29 - loss: 0.6298 - accuracy: 0.6493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 28/115 [======&gt;.......................] - ETA: 3:24 - loss: 0.6263 - accuracy: 0.6529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 29/115 [======&gt;.......................] - ETA: 3:19 - loss: 0.6270 - accuracy: 0.6541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 30/115 [======&gt;.......................] - ETA: 3:14 - loss: 0.6274 - accuracy: 0.6521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 31/115 [=======&gt;......................] - ETA: 3:09 - loss: 0.6250 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 32/115 [=======&gt;......................] - ETA: 3:05 - loss: 0.6256 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 33/115 [=======&gt;......................] - ETA: 3:01 - loss: 0.6258 - accuracy: 0.6572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34/115 [=======&gt;......................] - ETA: 2:57 - loss: 0.6258 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 35/115 [========&gt;.....................] - ETA: 2:53 - loss: 0.6247 - accuracy: 0.6571\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/115 [========&gt;.....................] - ETA: 2:49 - loss: 0.6254 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 37/115 [========&gt;.....................] - ETA: 2:45 - loss: 0.6242 - accuracy: 0.6588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/115 [========&gt;.....................] - ETA: 2:42 - loss: 0.6232 - accuracy: 0.6587\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 39/115 [=========&gt;....................] - ETA: 2:38 - loss: 0.6214 - accuracy: 0.6603\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 40/115 [=========&gt;....................] - ETA: 2:35 - loss: 0.6200 - accuracy: 0.6617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 41/115 [=========&gt;....................] - ETA: 2:32 - loss: 0.6181 - accuracy: 0.6639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/115 [=========&gt;....................] - ETA: 2:29 - loss: 0.6176 - accuracy: 0.6652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/115 [==========&gt;...................] - ETA: 2:26 - loss: 0.6162 - accuracy: 0.6657\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/115 [==========&gt;...................] - ETA: 2:23 - loss: 0.6168 - accuracy: 0.6662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/115 [==========&gt;...................] - ETA: 2:20 - loss: 0.6165 - accuracy: 0.6653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 46/115 [===========&gt;..................] - ETA: 2:17 - loss: 0.6158 - accuracy: 0.6644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 47/115 [===========&gt;..................] - ETA: 2:14 - loss: 0.6137 - accuracy: 0.6676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 48/115 [===========&gt;..................] - ETA: 2:12 - loss: 0.6113 - accuracy: 0.6699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 49/115 [===========&gt;..................] - ETA: 2:09 - loss: 0.6126 - accuracy: 0.6684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 50/115 [============&gt;.................] - ETA: 2:06 - loss: 0.6127 - accuracy: 0.6681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 51/115 [============&gt;.................] - ETA: 2:04 - loss: 0.6136 - accuracy: 0.6667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 52/115 [============&gt;.................] - ETA: 2:01 - loss: 0.6139 - accuracy: 0.6677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 53/115 [============&gt;.................] - ETA: 1:59 - loss: 0.6128 - accuracy: 0.6680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 54/115 [=============&gt;................] - ETA: 1:56 - loss: 0.6126 - accuracy: 0.6678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 55/115 [=============&gt;................] - ETA: 1:54 - loss: 0.6128 - accuracy: 0.6682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 56/115 [=============&gt;................] - ETA: 1:51 - loss: 0.6109 - accuracy: 0.6713\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 57/115 [=============&gt;................] - ETA: 1:49 - loss: 0.6105 - accuracy: 0.6721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 58/115 [==============&gt;...............] - ETA: 1:47 - loss: 0.6089 - accuracy: 0.6735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 59/115 [==============&gt;...............] - ETA: 1:44 - loss: 0.6076 - accuracy: 0.6764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 60/115 [==============&gt;...............] - ETA: 1:42 - loss: 0.6058 - accuracy: 0.6786\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 61/115 [==============&gt;...............] - ETA: 1:40 - loss: 0.6045 - accuracy: 0.6793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 62/115 [===============&gt;..............] - ETA: 1:38 - loss: 0.6011 - accuracy: 0.6815\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 63/115 [===============&gt;..............] - ETA: 1:35 - loss: 0.6005 - accuracy: 0.6815\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/115 [===============&gt;..............] - ETA: 1:33 - loss: 0.6008 - accuracy: 0.6821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 65/115 [===============&gt;..............] - ETA: 1:31 - loss: 0.5982 - accuracy: 0.6846\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 66/115 [================&gt;.............] - ETA: 1:29 - loss: 0.5978 - accuracy: 0.6861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 67/115 [================&gt;.............] - ETA: 1:27 - loss: 0.5979 - accuracy: 0.6856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 68/115 [================&gt;.............] - ETA: 1:25 - loss: 0.5957 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 69/115 [=================&gt;............] - ETA: 1:23 - loss: 0.5949 - accuracy: 0.6880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 70/115 [=================&gt;............] - ETA: 1:21 - loss: 0.5953 - accuracy: 0.6888\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 71/115 [=================&gt;............] - ETA: 1:19 - loss: 0.5943 - accuracy: 0.6884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/115 [=================&gt;............] - ETA: 1:17 - loss: 0.5950 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 73/115 [==================&gt;...........] - ETA: 1:15 - loss: 0.5956 - accuracy: 0.6871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 74/115 [==================&gt;...........] - ETA: 1:13 - loss: 0.5958 - accuracy: 0.6862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 75/115 [==================&gt;...........] - ETA: 1:11 - loss: 0.5962 - accuracy: 0.6854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 76/115 [==================&gt;...........] - ETA: 1:09 - loss: 0.5962 - accuracy: 0.6854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 77/115 [===================&gt;..........] - ETA: 1:07 - loss: 0.5949 - accuracy: 0.6863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 78/115 [===================&gt;..........] - ETA: 1:05 - loss: 0.5950 - accuracy: 0.6863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 79/115 [===================&gt;..........] - ETA: 1:03 - loss: 0.5941 - accuracy: 0.6871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 80/115 [===================&gt;..........] - ETA: 1:01 - loss: 0.5942 - accuracy: 0.6867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 81/115 [====================&gt;.........] - ETA: 59s - loss: 0.5938 - accuracy: 0.6875 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 82/115 [====================&gt;.........] - ETA: 57s - loss: 0.5929 - accuracy: 0.6886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 83/115 [====================&gt;.........] - ETA: 55s - loss: 0.5921 - accuracy: 0.6894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 84/115 [====================&gt;.........] - ETA: 54s - loss: 0.5903 - accuracy: 0.6916\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/115 [=====================&gt;........] - ETA: 52s - loss: 0.5885 - accuracy: 0.6934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 86/115 [=====================&gt;........] - ETA: 50s - loss: 0.5863 - accuracy: 0.6955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 87/115 [=====================&gt;........] - ETA: 48s - loss: 0.5849 - accuracy: 0.6965\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/115 [=====================&gt;........] - ETA: 46s - loss: 0.5824 - accuracy: 0.6974\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 89/115 [======================&gt;.......] - ETA: 44s - loss: 0.5800 - accuracy: 0.6987\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 90/115 [======================&gt;.......] - ETA: 43s - loss: 0.5771 - accuracy: 0.7007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 91/115 [======================&gt;.......] - ETA: 41s - loss: 0.5759 - accuracy: 0.7016\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/115 [=======================&gt;......] - ETA: 39s - loss: 0.5739 - accuracy: 0.7041\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 93/115 [=======================&gt;......] - ETA: 37s - loss: 0.5730 - accuracy: 0.7046\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 94/115 [=======================&gt;......] - ETA: 35s - loss: 0.5724 - accuracy: 0.7051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 95/115 [=======================&gt;......] - ETA: 34s - loss: 0.5703 - accuracy: 0.7069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/115 [========================&gt;.....] - ETA: 32s - loss: 0.5685 - accuracy: 0.7080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 97/115 [========================&gt;.....] - ETA: 30s - loss: 0.5673 - accuracy: 0.7088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 98/115 [========================&gt;.....] - ETA: 28s - loss: 0.5662 - accuracy: 0.7098\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 99/115 [========================&gt;.....] - ETA: 27s - loss: 0.5657 - accuracy: 0.7105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/115 [=========================&gt;....] - ETA: 25s - loss: 0.5650 - accuracy: 0.7106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r101/115 [=========================&gt;....] - ETA: 23s - loss: 0.5641 - accuracy: 0.7110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102/115 [=========================&gt;....] - ETA: 21s - loss: 0.5626 - accuracy: 0.7120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r103/115 [=========================&gt;....] - ETA: 20s - loss: 0.5607 - accuracy: 0.7130\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r104/115 [==========================&gt;...] - ETA: 18s - loss: 0.5591 - accuracy: 0.7139\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r105/115 [==========================&gt;...] - ETA: 16s - loss: 0.5569 - accuracy: 0.7149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r106/115 [==========================&gt;...] - ETA: 15s - loss: 0.5567 - accuracy: 0.7158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/115 [==========================&gt;...] - ETA: 13s - loss: 0.5557 - accuracy: 0.7158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/115 [===========================&gt;..] - ETA: 11s - loss: 0.5541 - accuracy: 0.7167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r109/115 [===========================&gt;..] - ETA: 10s - loss: 0.5528 - accuracy: 0.7179\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r110/115 [===========================&gt;..] - ETA: 8s - loss: 0.5525 - accuracy: 0.7182 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/115 [===========================&gt;..] - ETA: 6s - loss: 0.5521 - accuracy: 0.7176\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r112/115 [============================&gt;.] - ETA: 4s - loss: 0.5494 - accuracy: 0.7193\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r113/115 [============================&gt;.] - ETA: 3s - loss: 0.5494 - accuracy: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r114/115 [============================&gt;.] - ETA: 1s - loss: 0.5485 - accuracy: 0.7196\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 200s 2s/step - loss: 0.5477 - accuracy: 0.7197 - val_loss: 0.4123 - val_accuracy: 0.8260\nEpoch 2/2\n\r  1/115 [..............................] - ETA: 2:44 - loss: 0.3183 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2/115 [..............................] - ETA: 2:42 - loss: 0.3191 - accuracy: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  3/115 [..............................] - ETA: 2:40 - loss: 0.3396 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/115 [&gt;.............................] - ETA: 2:38 - loss: 0.3738 - accuracy: 0.8359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5/115 [&gt;.............................] - ETA: 2:37 - loss: 0.4268 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  6/115 [&gt;.............................] - ETA: 2:35 - loss: 0.4511 - accuracy: 0.7969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/115 [&gt;.............................] - ETA: 2:34 - loss: 0.4398 - accuracy: 0.8080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  8/115 [=&gt;............................] - ETA: 2:32 - loss: 0.4249 - accuracy: 0.8164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  9/115 [=&gt;............................] - ETA: 2:31 - loss: 0.4271 - accuracy: 0.8160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 10/115 [=&gt;............................] - ETA: 2:29 - loss: 0.4394 - accuracy: 0.8000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 11/115 [=&gt;............................] - ETA: 2:28 - loss: 0.4479 - accuracy: 0.7926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 12/115 [==&gt;...........................] - ETA: 2:27 - loss: 0.4397 - accuracy: 0.7995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13/115 [==&gt;...........................] - ETA: 2:25 - loss: 0.4493 - accuracy: 0.7981\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 14/115 [==&gt;...........................] - ETA: 2:24 - loss: 0.4605 - accuracy: 0.7879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 15/115 [==&gt;...........................] - ETA: 2:22 - loss: 0.4601 - accuracy: 0.7896\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 16/115 [===&gt;..........................] - ETA: 2:21 - loss: 0.4555 - accuracy: 0.7930\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 17/115 [===&gt;..........................] - ETA: 2:19 - loss: 0.4529 - accuracy: 0.7923\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 18/115 [===&gt;..........................] - ETA: 2:18 - loss: 0.4490 - accuracy: 0.7951\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 19/115 [===&gt;..........................] - ETA: 2:16 - loss: 0.4454 - accuracy: 0.7928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 20/115 [====&gt;.........................] - ETA: 2:15 - loss: 0.4385 - accuracy: 0.7953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 21/115 [====&gt;.........................] - ETA: 2:14 - loss: 0.4339 - accuracy: 0.7976\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 22/115 [====&gt;.........................] - ETA: 2:12 - loss: 0.4283 - accuracy: 0.7983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 23/115 [=====&gt;........................] - ETA: 2:11 - loss: 0.4268 - accuracy: 0.7989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 24/115 [=====&gt;........................] - ETA: 2:09 - loss: 0.4304 - accuracy: 0.7956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 25/115 [=====&gt;........................] - ETA: 2:08 - loss: 0.4225 - accuracy: 0.8000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26/115 [=====&gt;........................] - ETA: 2:07 - loss: 0.4183 - accuracy: 0.8041\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 27/115 [======&gt;.......................] - ETA: 2:05 - loss: 0.4122 - accuracy: 0.8079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 28/115 [======&gt;.......................] - ETA: 2:04 - loss: 0.4114 - accuracy: 0.8092\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 29/115 [======&gt;.......................] - ETA: 2:02 - loss: 0.4120 - accuracy: 0.8082\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 30/115 [======&gt;.......................] - ETA: 2:01 - loss: 0.4113 - accuracy: 0.8073\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 31/115 [=======&gt;......................] - ETA: 1:59 - loss: 0.4092 - accuracy: 0.8075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 32/115 [=======&gt;......................] - ETA: 1:58 - loss: 0.4064 - accuracy: 0.8096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 33/115 [=======&gt;......................] - ETA: 1:57 - loss: 0.4081 - accuracy: 0.8087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34/115 [=======&gt;......................] - ETA: 1:55 - loss: 0.4048 - accuracy: 0.8079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 35/115 [========&gt;.....................] - ETA: 1:54 - loss: 0.4002 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/115 [========&gt;.....................] - ETA: 1:52 - loss: 0.3988 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 37/115 [========&gt;.....................] - ETA: 1:51 - loss: 0.3978 - accuracy: 0.8117\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/115 [========&gt;.....................] - ETA: 1:49 - loss: 0.4034 - accuracy: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 39/115 [=========&gt;....................] - ETA: 1:48 - loss: 0.4010 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 40/115 [=========&gt;....................] - ETA: 1:47 - loss: 0.4003 - accuracy: 0.8133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 41/115 [=========&gt;....................] - ETA: 1:45 - loss: 0.3963 - accuracy: 0.8148\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/115 [=========&gt;....................] - ETA: 1:44 - loss: 0.3946 - accuracy: 0.8170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/115 [==========&gt;...................] - ETA: 1:42 - loss: 0.3917 - accuracy: 0.8183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/115 [==========&gt;...................] - ETA: 1:41 - loss: 0.3880 - accuracy: 0.8203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/115 [==========&gt;...................] - ETA: 1:39 - loss: 0.3865 - accuracy: 0.8201\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 46/115 [===========&gt;..................] - ETA: 1:38 - loss: 0.3828 - accuracy: 0.8234\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 47/115 [===========&gt;..................] - ETA: 1:37 - loss: 0.3830 - accuracy: 0.8225\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 48/115 [===========&gt;..................] - ETA: 1:35 - loss: 0.3797 - accuracy: 0.8255\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 49/115 [===========&gt;..................] - ETA: 1:34 - loss: 0.3794 - accuracy: 0.8265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 50/115 [============&gt;.................] - ETA: 1:32 - loss: 0.3780 - accuracy: 0.8263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 51/115 [============&gt;.................] - ETA: 1:31 - loss: 0.3781 - accuracy: 0.8266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 52/115 [============&gt;.................] - ETA: 1:29 - loss: 0.3800 - accuracy: 0.8263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 53/115 [============&gt;.................] - ETA: 1:28 - loss: 0.3771 - accuracy: 0.8278\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 54/115 [=============&gt;................] - ETA: 1:27 - loss: 0.3764 - accuracy: 0.8293\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 55/115 [=============&gt;................] - ETA: 1:25 - loss: 0.3734 - accuracy: 0.8307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 56/115 [=============&gt;................] - ETA: 1:24 - loss: 0.3736 - accuracy: 0.8298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 57/115 [=============&gt;................] - ETA: 1:22 - loss: 0.3725 - accuracy: 0.8295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 58/115 [==============&gt;...............] - ETA: 1:21 - loss: 0.3710 - accuracy: 0.8308\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 59/115 [==============&gt;...............] - ETA: 1:19 - loss: 0.3705 - accuracy: 0.8305\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 60/115 [==============&gt;...............] - ETA: 1:18 - loss: 0.3702 - accuracy: 0.8307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 61/115 [==============&gt;...............] - ETA: 1:17 - loss: 0.3704 - accuracy: 0.8309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 62/115 [===============&gt;..............] - ETA: 1:15 - loss: 0.3694 - accuracy: 0.8317\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 63/115 [===============&gt;..............] - ETA: 1:14 - loss: 0.3662 - accuracy: 0.8338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/115 [===============&gt;..............] - ETA: 1:12 - loss: 0.3657 - accuracy: 0.8340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 65/115 [===============&gt;..............] - ETA: 1:11 - loss: 0.3636 - accuracy: 0.8351\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 66/115 [================&gt;.............] - ETA: 1:09 - loss: 0.3627 - accuracy: 0.8357\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 67/115 [================&gt;.............] - ETA: 1:08 - loss: 0.3629 - accuracy: 0.8358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 68/115 [================&gt;.............] - ETA: 1:07 - loss: 0.3599 - accuracy: 0.8378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 69/115 [=================&gt;............] - ETA: 1:05 - loss: 0.3585 - accuracy: 0.8383\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 70/115 [=================&gt;............] - ETA: 1:04 - loss: 0.3561 - accuracy: 0.8397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 71/115 [=================&gt;............] - ETA: 1:02 - loss: 0.3538 - accuracy: 0.8407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/115 [=================&gt;............] - ETA: 1:01 - loss: 0.3542 - accuracy: 0.8411\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 73/115 [==================&gt;...........] - ETA: 59s - loss: 0.3530 - accuracy: 0.8416 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 74/115 [==================&gt;...........] - ETA: 58s - loss: 0.3514 - accuracy: 0.8421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 75/115 [==================&gt;...........] - ETA: 57s - loss: 0.3510 - accuracy: 0.8425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 76/115 [==================&gt;...........] - ETA: 55s - loss: 0.3506 - accuracy: 0.8429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 77/115 [===================&gt;..........] - ETA: 54s - loss: 0.3490 - accuracy: 0.8442\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 78/115 [===================&gt;..........] - ETA: 52s - loss: 0.3478 - accuracy: 0.8450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 79/115 [===================&gt;..........] - ETA: 51s - loss: 0.3467 - accuracy: 0.8461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 80/115 [===================&gt;..........] - ETA: 49s - loss: 0.3439 - accuracy: 0.8477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 81/115 [====================&gt;.........] - ETA: 48s - loss: 0.3405 - accuracy: 0.8495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 82/115 [====================&gt;.........] - ETA: 47s - loss: 0.3404 - accuracy: 0.8498\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 83/115 [====================&gt;.........] - ETA: 45s - loss: 0.3393 - accuracy: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 84/115 [====================&gt;.........] - ETA: 44s - loss: 0.3363 - accuracy: 0.8523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/115 [=====================&gt;........] - ETA: 42s - loss: 0.3371 - accuracy: 0.8522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 86/115 [=====================&gt;........] - ETA: 41s - loss: 0.3346 - accuracy: 0.8536\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 87/115 [=====================&gt;........] - ETA: 39s - loss: 0.3317 - accuracy: 0.8549\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/115 [=====================&gt;........] - ETA: 38s - loss: 0.3286 - accuracy: 0.8565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 89/115 [======================&gt;.......] - ETA: 37s - loss: 0.3259 - accuracy: 0.8578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 90/115 [======================&gt;.......] - ETA: 35s - loss: 0.3273 - accuracy: 0.8576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 91/115 [======================&gt;.......] - ETA: 34s - loss: 0.3259 - accuracy: 0.8585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/115 [=======================&gt;......] - ETA: 32s - loss: 0.3277 - accuracy: 0.8580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 93/115 [=======================&gt;......] - ETA: 31s - loss: 0.3246 - accuracy: 0.8595\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 94/115 [=======================&gt;......] - ETA: 29s - loss: 0.3224 - accuracy: 0.8607\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 95/115 [=======================&gt;......] - ETA: 28s - loss: 0.3201 - accuracy: 0.8618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/115 [========================&gt;.....] - ETA: 27s - loss: 0.3187 - accuracy: 0.8630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 97/115 [========================&gt;.....] - ETA: 25s - loss: 0.3192 - accuracy: 0.8631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 98/115 [========================&gt;.....] - ETA: 24s - loss: 0.3172 - accuracy: 0.8638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 99/115 [========================&gt;.....] - ETA: 22s - loss: 0.3145 - accuracy: 0.8652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/115 [=========================&gt;....] - ETA: 21s - loss: 0.3131 - accuracy: 0.8659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r101/115 [=========================&gt;....] - ETA: 19s - loss: 0.3113 - accuracy: 0.8670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102/115 [=========================&gt;....] - ETA: 18s - loss: 0.3094 - accuracy: 0.8680\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r103/115 [=========================&gt;....] - ETA: 17s - loss: 0.3084 - accuracy: 0.8686\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r104/115 [==========================&gt;...] - ETA: 15s - loss: 0.3077 - accuracy: 0.8690\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r105/115 [==========================&gt;...] - ETA: 14s - loss: 0.3057 - accuracy: 0.8699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r106/115 [==========================&gt;...] - ETA: 12s - loss: 0.3055 - accuracy: 0.8700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/115 [==========================&gt;...] - ETA: 11s - loss: 0.3036 - accuracy: 0.8709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/115 [===========================&gt;..] - ETA: 9s - loss: 0.3027 - accuracy: 0.8709 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r109/115 [===========================&gt;..] - ETA: 8s - loss: 0.3012 - accuracy: 0.8716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r110/115 [===========================&gt;..] - ETA: 7s - loss: 0.2994 - accuracy: 0.8727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/115 [===========================&gt;..] - ETA: 5s - loss: 0.2988 - accuracy: 0.8727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r112/115 [============================&gt;.] - ETA: 4s - loss: 0.2977 - accuracy: 0.8733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r113/115 [============================&gt;.] - ETA: 2s - loss: 0.2965 - accuracy: 0.8736\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r114/115 [============================&gt;.] - ETA: 1s - loss: 0.2947 - accuracy: 0.8745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 170s 1s/step - loss: 0.2925 - accuracy: 0.8751 - val_loss: 0.4165 - val_accuracy: 0.8529\n</div>"]}}],"execution_count":75},{"cell_type":"code","source":["model.save_pretrained('/tmp/mrpc')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":76},{"cell_type":"code","source":["tokenizer.save_pretrained('/tmp/mrpc')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[33]: (&#39;/tmp/mrpc/vocab.txt&#39;,\n &#39;/tmp/mrpc/special_tokens_map.json&#39;,\n &#39;/tmp/mrpc/added_tokens.json&#39;)</div>"]}}],"execution_count":77},{"cell_type":"code","source":["%fs\ncp -r file:/tmp/mrpc dbfs:/ml/judith/transformers/mrpc/1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res20: Boolean = true\n</div>"]}}],"execution_count":78},{"cell_type":"code","source":["%fs\nls dbfs:/ml/judith/transformers/mrpc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/ml/judith/transformers/mrpc/1/</td><td>1/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/2/</td><td>2/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/transformers/mrpc/config.json</td><td>config.json</td><td>543</td></tr></tbody></table></div>"]}}],"execution_count":79},{"cell_type":"code","source":["model1 = TFBertForSequenceClassification.from_pretrained(\"/tmp/mrpc\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":80},{"cell_type":"code","source":["sentence_0 = \"This research was consistent with his findings.\"\nsentence_1 = \"His findings were compatible with this research.\"\nsentence_2 = \"His findings were not compatible with this research.\"\ninputs_1 = tokenizer.encode_plus(sentence_0, sentence_1, add_special_tokens=True, return_tensors='tf')\ninputs_2 = tokenizer.encode_plus(sentence_0, sentence_2, add_special_tokens=True, return_tensors='tf')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":81},{"cell_type":"code","source":["model1(inputs_1)[0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[42]: &lt;tf.Tensor: id=73262, shape=(1, 2), dtype=float32, numpy=array([[-1.7221127,  2.6670885]], dtype=float32)&gt;</div>"]}}],"execution_count":82},{"cell_type":"code","source":["model1(inputs_2)[0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[43]: &lt;tf.Tensor: id=75431, shape=(1, 2), dtype=float32, numpy=array([[-1.6031767,  2.5245368]], dtype=float32)&gt;</div>"]}}],"execution_count":83},{"cell_type":"markdown","source":["How to download GLUE dataset?"],"metadata":{}},{"cell_type":"code","source":["%sh\ncurl https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py --output /tmp/download_glue_data.py"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100  8225  100  8225    0     0  25427      0 --:--:-- --:--:-- --:--:-- 25464\n</div>"]}}],"execution_count":85},{"cell_type":"code","source":["%fs\ncp -r file:/databricks/driver/glue_data dbfs:/ml/judith/datasets/glue_data"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res10: Boolean = true\n</div>"]}}],"execution_count":86},{"cell_type":"code","source":["%fs\nls dbfs:/ml/judith/datasets/glue_data"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/ml/judith/datasets/glue_data/CoLA/</td><td>CoLA/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/MNLI/</td><td>MNLI/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/MRPC/</td><td>MRPC/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/QNLI/</td><td>QNLI/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/QQP/</td><td>QQP/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/RTE/</td><td>RTE/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/SNLI/</td><td>SNLI/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/SST-2/</td><td>SST-2/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/STS-B/</td><td>STS-B/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/WNLI/</td><td>WNLI/</td><td>0</td></tr><tr><td>dbfs:/ml/judith/datasets/glue_data/diagnostic/</td><td>diagnostic/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":87},{"cell_type":"code","source":["%sh\n/databricks/python/bin/python -V\n/databricks/python/bin/python /tmp/download_glue_data.py"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python 3.7.3\nDownloading and extracting CoLA...\n\tCompleted!\nDownloading and extracting SST...\n\tCompleted!\nProcessing MRPC...\nLocal MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n\tCompleted!\nDownloading and extracting QQP...\n\tCompleted!\nDownloading and extracting STS...\n\tCompleted!\nDownloading and extracting MNLI...\n\tCompleted!\nDownloading and extracting SNLI...\n\tCompleted!\nDownloading and extracting QNLI...\n\tCompleted!\nDownloading and extracting RTE...\n\tCompleted!\nDownloading and extracting WNLI...\n\tCompleted!\nDownloading and extracting diagnostic...\n\tCompleted!\n</div>"]}}],"execution_count":88},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":89}],"metadata":{"name":"transformers scratchpad","notebookId":144978},"nbformat":4,"nbformat_minor":0}
